# https://taskfile.dev

version: '3'

vars:
  BLAZEGRAPH_ENDPOINT: http://blazegraph:8080/blazegraph/sparql
  BLAZEGRAPH_ENDPOINT_SECONDARY: http://blazegraph-secondary:8080/blazegraph/sparql
  BLAZEGRAPH_BACKUP: http://blazegraph:8080/blazegraph/backup
  GENERATOR_POLICY: /mapping/generator-policy.xml
  MAPPING_BATCH_SIZE: 10
  NAMESPACE: https://data.skkg.ch/

output: 'prefixed'

tasks:

  default:
    desc: Runs the entire pipeline
    cmds:
      - task: download-source-items
      - task: prepare-and-perform-mapping
      - task: ingest-items
      - task: ingest-classifications
      - task: ingest-ontologies
      - task: retrieve-and-ingest-additional-data

  create-blazegraph-backup:
    desc: Creates a compressed Blazegraph backup
    vars:
      FILENAME:
        sh: echo "/backup/blazegraph-$(date -u "+%Y-%m-%d-%H-%M-%S").jnl.gz"
    cmds:
       - curl --data-urlencode "file={{.FILENAME}}" --data-urlencode "compress=true" --data-urlencode "block=true" {{.BLAZEGRAPH_BACKUP}}  
      

  download-source-items:
    desc: Downloads all item records from MuseumPlus
    deps:
      - download-address-items
      - download-literature-items
      - download-object-items
      - download-person-items
      - download-multimedia-items
  
  download-source-vocabularies:
    desc: Downloads all vocabularies from MuseumPlus
    cmds:
      - for:
          - GenCurrencyVgr
          - GenLanguageVgr
          - GenLocationVgr
          - GenMoveStatusVgr
          - LitAuthorTypeVgr
          - LitLanguageVgr
          - LitTypeVgr
          - LitPlaceVgr
          - MulTypeVgr
          - ObjCategoryVgr
          - ObjDatePeriodVgr
          - ObjDatePrefixVgr
          - ObjDateSourceVgr
          - ObjDateSuffixVgr
          - ObjDateTypeVgr
          - ObjIconographyVgr
          - ObjIconographyTypeVgr
          - ObjInscriptionDialogTypeVgr
          - ObjInscriptionTypeVgr
          - ObjInscriptionPositionVgr
          - ObjMaterialVgr
          - ObjMaterialTechniqueVgr
          - ObjMaterialTechniqueTypeVgr
          - ObjObjectTitleTypeVgr
          - ObjObjectTitleSourceVgr
          - ObjObjectTypeVgr
          - ObjPerAssociationRoleVgr
          - ObjPerAssociationAttributionVgr
          - PerTypeVgr
        task: _download-vocabulary-from-museumplus
        vars:
          VOCABULARY: "{{.ITEM}}"
          
  download-address-items:
    desc: Download the address item records from MuseumPlus
    cmds:
      - task: _download-module-items-from-museumplus
        vars:
          MODULE: Address

  download-literature-items:
    desc: Download the literature item records from MuseumPlus
    cmds:
      - task: _download-module-items-from-museumplus
        vars:
          MODULE: Literature

  download-object-items:
    desc: Download the object item records from MuseumPlus
    cmds:
      - task: _download-module-items-from-museumplus
        vars:
          MODULE: Object

  download-multimedia-items:
    desc: Download the multimedia item records from MuseumPlus
    cmds:
      - task: _download-module-items-from-museumplus
        vars:
          MODULE: Multimedia

  download-person-items:
    desc: Download the person item records from MuseumPlus
    cmds:
      - task: _download-module-items-from-museumplus
        vars:
          MODULE: Person

  execute-query-from-file:
    desc: Execute a query against the main Blazegraph instance. Pass the path to the file as command line argument
    cmds:
      - |
        curl -X POST -H "Accept: text/csv" --data-urlencode "query=$(cat "{{.CLI_ARGS}}")" {{.BLAZEGRAPH_ENDPOINT}}

  first-run:
    desc: Task to run when the pipeline is run for the first time
    cmds:
      - task: update-vocabularies
      - task: ingest-platform-data

  generate-example-record-object:
    desc: Generates an example Object record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-object-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          INPUTFILES: /data/source/object/object-item-3412c1a2-3c87-462a-8943-34aede5dcf5a.xml /data/source/object/object-item-2a0c8fab-5771-496c-9350-5482f50c93e2.xml /data/source/object/object-item-0a5b9c6a-2d1d-43c5-b833-6975ddfa7ded.xml /data/source/object/object-item-3c7215d0-3aba-4bb8-98e6-5da239ab0a64.xml /data/source/object/object-item-0b17827d-117b-42b7-9925-0731f6db779b.xml /data/source/object/object-item-0a0c96ab-71f1-466a-a5ff-ab556d437f15.xml /data/source/object/object-item-ffa356cf-f988-4d96-9580-92dcb0e4dddf.xml
  
  generate-example-record-literature:
    desc: Generates an example Literature record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-literature-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          INPUTFILES: /data/source/literature/literature-item-0a1ab550-dabb-4afd-be17-f0f43725be33.xml /data/source/literature/literature-item-0b7ee850-6fd8-45ba-af19-267548c9c4cf.xml
  
  generate-example-record-multimedia:
    desc: Generates an example Multimedia record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-multimedia-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          INPUTFILES: /data/source/multimedia/multimedia-item-2270.xml /data/source/multimedia/multimedia-item-8727.xml

  generate-example-record-person:
    desc: Generates an example Person record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-person-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          INPUTFILES: /data/source/person/person-item-1111.xml /data/source/person/person-item-88c3cca8-a587-44b8-8c6d-194dd285b1dd.xml /data/source/person/person-item-0d2611a7-961e-420a-8b04-dc628c3f70fb.xml /data/source/person/person-item-f447a4d2-7be1-4d7c-8dcb-64381b20a9bc.xml

  generate-field-definitions:
    desc: Generates the field definitions for the platform based on the fieldDefinitions.yml file
    sources:
      - /apps/skkg/src/fieldDefinitions.yml
    vars:
      INPUTFILE: /apps/skkg/src/fieldDefinitions.yml
      JSONOUTPUT: /apps/skkg/data/templates/https%3A%2F%2Fstatic.swissartresearch.net%2Fpartial%2FfieldDefinitions.html
      INLINEOUTPUT: /apps/skkg/data/templates/https%3A%2F%2Fstatic.swissartresearch.net%2Fpartial%2FfieldDefinitionsInline.html
    cmds:
      - semantic-field-util -f JSON -y {{.INPUTFILE}}  write -t {{.JSONOUTPUT}}
      - semantic-field-util -f INLINE -y {{.INPUTFILE}}  write -t {{.INLINEOUTPUT}}
  
  ingest-classifications:
    desc: Ingest classifications into the triplestore
    sources:
      - /data/ttl/additional/classifications/*.ttl
    cmds:
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME:
            sh: echo "$(basename {{.ITEM}} .ttl)"
          FILE: "{{.ITEM}}"
          TYPE: application/x-turtle
          GRAPH: 
            sh: echo "{{.NAMESPACE}}graph/classifications/$(basename {{.ITEM}} .ttl)"
          ENDPOINT: "{{.BLAZEGRAPH_ENDPOINT_SECONDARY}}"
  
  ingest-items:
    desc: Ingest items for all modules. Add --debug true To see the response from the triplestore
    cmds:
      - task: ingest-object-items
      - task: ingest-person-items
      - task: ingest-multimedia-items
      - task: ingest-literature-items

  ingest-literature-items:
    desc: Ingests the literature items into the triplestore
    cmds:
      - task: _ingest_module_items
        vars:
          MODULE: Literature

  ingest-multimedia-items:
    desc: Ingests the multimedia items into the triplestore
    cmds:
      - task: _ingest_module_items
        vars:
          MODULE: Multimedia

  ingest-object-items:
    desc: Ingests the object items into the triplestore
    cmds:
      - task: _ingest_module_items
        vars:
          MODULE: Object
  
  ingest-ontologies:
    desc: Ingests the ontologies into individual named Graphs
    sources:
      - /mapping/schemas/*.*
    cmds:
      - task: _ingest-data-from-file
        vars:
          NAME: CIDOC-CRM
          FILE: /mapping/schemas/CIDOC_CRM_7.1.1_RDFS_Impl_v1.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/cidoc-crm/
      - task: _ingest-data-from-file
        vars:
          NAME: CRMdig
          FILE: /mapping/schemas/CRMdig_v3.2.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.ics.forth.gr/isl/CRMdig/
      - task: _ingest-data-from-file
        vars:
          NAME: CRMsci
          FILE: /mapping/schemas/CRMsci_v2.0.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/extensions/crmsci/
      - task: _ingest-data-from-file
        vars:
          NAME: Linked.Art
          FILE: /mapping/schemas/LinkedArt.rdfs
          TYPE: application/rdf+xml
          GRAPH: https://linked.art/ns/terms/
      - task: _ingest-data-from-file
        vars:
          NAME: SKKG Ontology
          FILE: /mapping/schemas/skkg-ontology.ttl
          TYPE: application/x-turtle
          GRAPH: http://ontology.skkg.ch/ontology/

  ingest-platform-data:
    desc: Ingests the data used for the operation of the platform
    sources:
      - /data/platform/*.trig
    cmds: 
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME: "{{.ITEM}}"
          FILE: "{{.ITEM}}"
          TYPE: application/x-trig

  ingest-person-items:
    desc: Ingests the person items into the triplestore
    cmds:
      - task: _ingest_module_items
        vars:
          MODULE: Person
    
  ingest-vocabularies:
    - task: _ingest_vocabularies
      vars:
        INPUTFOLDER: /data/ttl/main/vocabularies
        NAMESPACE: https://data.skkg.ch/type/

  prepare-and-perform-mapping:
    desc: Prepares and performs the mapping for all modules
    cmds:
      - echo "Preparing mapping..."
      - task: prepare-mapping-for-object-items
      - task: prepare-mapping-for-person-items
      - task: prepare-mapping-for-multimedia-items
      - task: prepare-mapping-for-literature-items
      - echo "Mapping..."
      - task: perform-mapping-for-object-items
      - task: perform-mapping-for-person-items
      - task: perform-mapping-for-multimedia-items
      - task: perform-mapping-for-literature-items

  perform-mapping-for-literature-items:
    desc: Performs the mapping for the literature items
    cmds:
      - task: _perform-mapping-for-module-items
        vars:
          MODULE: Literature

  perform-mapping-for-multimedia-items:
    desc: Performs the mapping for the multimedia items
    cmds:
      - task: _perform-mapping-for-module-items
        vars:
          MODULE: Multimedia

  perform-mapping-for-object-items:
    desc: Performs the mapping for the object items
    cmds:
      - task: _perform-mapping-for-module-items
        vars:
          MODULE: Object
  
  perform-mapping-for-person-items:
    desc: Performs the mapping for the person items
    cmds:
      - task: _perform-mapping-for-module-items
        vars:
          MODULE: Person

  perform-mapping-for-vocabularies:
    desc: Performs the mapping for the vocabularies
    source:
      - /mapping/mapping-vocabulary.x3ml
      - /data/source/vocabularies/*.xml
    vars:
      SOURCEFOLDER: "/data/source/vocabularies"
      INPUTFOLDER: "/mapping/input/vocabularies"
      OUTPUTFOLDER: "/data/ttl/main/vocabularies"
      MAPPINGFILE: "/mapping/mapping-vocabulary.x3ml"
    cmds:
      - mkdir -p {{.INPUTFOLDER}}
      - mkdir -p {{.OUTPUTFOLDER}}
      - # Copy all XML files from the source folder to the input folder
      - find {{.SOURCEFOLDER}} -maxdepth 1 -name "*.xml" -exec cp -t {{.INPUTFOLDER}} {} +
      - # Remove the string 'xmlns="http://www.zetcom.com/ria/ws/vocabulary"' from the XML files in the input folder as X3ML is not able to handle XML namespaces
      - find {{.INPUTFOLDER}} -maxdepth 1 -name "*.xml" -exec sed -i 's/xmlns="http:\/\/www.zetcom.com\/ria\/ws\/vocabulary"//g' {} +
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -delete
      - bash /scripts/performMapping.sh -i {{.INPUTFOLDER}} -o {{.OUTPUTFOLDER}} -m {{.MAPPINGFILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}
  
  prepare-mapping-for-address-items:
    desc: Prepares the mapping for the object items
    cmds:
      - task: _prepare-mapping-for-module-items
        vars:
          MODULE: Address
  
  prepare-mapping-for-literature-items:
    desc: Prepares the mapping for the literature items
    cmds:
      - task: _prepare-mapping-for-module-items
        vars:
          MODULE: Literature
  
  prepare-mapping-for-multimedia-items:
    desc: Prepares the mapping for the multimedia items
    cmds:
      - task: _prepare-mapping-for-module-items
        vars:
          MODULE: Multimedia
  
  prepare-mapping-for-object-items:
    desc: Prepares the mapping for the object items
    cmds:
      - task: _prepare-mapping-for-module-items
        vars:
          MODULE: Object

  prepare-mapping-for-person-items:
    desc: Prepares the mapping for the person items
    cmds:
      - task: _prepare-mapping-for-module-items
        vars:
          MODULE: Person

  recreate-folder-metadata:
    desc: Recreate the metadata for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
    cmds:
      - rm -f /data/source/{{.MODULE}}/metadata.json
      - python /scripts/recreateMetadata.py --folder /data/source/{{.MODULE}}

  remove-deleted-address-items:
    desc: Removes address item records that have been deleted from MuseumPlus
    cmds:
      - task: _remove-deleted-module-items
        vars:
          MODULE: Address

  remove-deleted-literature-items:
    desc: Removes literature item records that have been deleted from MuseumPlus
    cmds:
      - task: _remove-deleted-module-items
        vars:
          MODULE: Literature

  remove-deleted-multimedia-items:
    desc: Removes multimedia item records that have been deleted from MuseumPlus
    cmds:
      - task: _remove-deleted-module-items
        vars:
          MODULE: Multimedia

  remove-deleted-object-items:
    desc: Removes object item records that have been deleted from MuseumPlus
    cmds:
      - task: _remove-deleted-module-items
        vars:
          MODULE: Object

  remove-deleted-person-items:
    desc: Removes person item records that have been deleted from MuseumPlus
    cmds:
      - task: _remove-deleted-module-items
        vars:
          MODULE: Person

  remove-deleted-source-items:
    desc: Removes item records that have been deleted from MuseumPlus
    deps:
      - remove-deleted-address-items
      - remove-deleted-literature-items
      - remove-deleted-object-items
      - remove-deleted-person-items

  retrieve-and-ingest-additional-data:
    desc: Retrieve and ingest additional data for external URIs in the Triple Store 
    interactive: True
    vars:
      OUTPUTFOLDER: /data/ttl/additional/external
      PREDICATES: http://www.ics.forth.gr/isl/CRMdig/L54_is_same-as,http://www.cidoc-crm.org/cidoc-crm/P2_has_type
      SOURCES: gnd,aat
      INGEST: True
      INGESTUPDATE: True
      INGESTNAMESPACE: https://data.skkg.ch/graph/externalData/
    cmds:
      - python /scripts/retrieveAdditionalData.py --endpoint {{.BLAZEGRAPH_ENDPOINT}} --outputFolder {{.OUTPUTFOLDER}} --predicates "{{.PREDICATES}}" --ingest {{.INGEST}} --ingestNamespace {{.INGESTNAMESPACE}} --ingestUpdate {{.INGESTUPDATE}}

  reset:
    desc: Delete all artefacts produced by the pipeline.
    prompt: This will delete all artefacts produced by the pipeline... Do you want to continue?
    cmds:
      - rm -f /scripts/.task/checksum/*
      - for:
          - address
          - literature
          - multimedia
          - object
          - person
        task: reset-module
        vars:
          MODULE: "{{.ITEM}}"
      - task: reset-vocabularies
      - echo "Done!"

  reset-module:
    desc: Delete all artefacts produced by the pipeline for a given module. The module name should be passed as an argument or via the MODULE variable.
    silent: true
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_LOWERCASE:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - |
        if [ -z "{{.MODULE}}" ]; then
          echo "No module specified as variable or cli argument. Exiting script."
          exit 1
        fi
      - echo "Deleting files for {{.MODULE}}..."
      - rm -rf /data/temp/download/temp_{{.MODULE_UCFIRST}}
      - rm -rf /data/temp/ingest/{{.MODULE_LOWERCASE}}
      - rm -rf /data/ttl/main/{{.MODULE_LOWERCASE}}
      - rm -rf /mapping/input/{{.MODULE_LOWERCASE}}
      - rm -rf /mapping/output/{{.MODULE_LOWERCASE}}
      - echo "Resetting metadata for {{.MODULE}}.."
      - task: recreate-folder-metadata
        vars:
          MODULE: "{{.MODULE_LOWERCASE}}"

  reset-vocabularies:
    desc: Delete all artefacts produced by the pipeline for the vocabularies.
    cmds: 
      - rm -rf /data/ttl/main/vocabularies
      - rm -rf /mapping/input/vocabularies
      - rm -rf /mapping/output/vocabularies

  reset-last-ingested-metadata:
    desc: Resets the last ingested metadata for a specific module. The module name should be passed as an argument.
    vars:
      MODULE: "{{.CLI_ARGS}}"
      SOURCEFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastIngested
          VALUE: "1970-01-01 00:00:00.000"
          SOURCEFOLDER: "{{.SOURCEFOLDER}}"
          FILEEXTENSION: .xml

  reset-last-mapped-metadata:
    desc: Resets the last mapped metadata for a specific module. The module name should be passed as an argument.
    vars:
      MODULE: "{{.CLI_ARGS}}"
      SOURCEFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastMapped
          VALUE: "1970-01-01 00:00:00.000"
          SOURCEFOLDER: "{{.SOURCEFOLDER}}"
          FILEEXTENSION: .xml
  
  suggest-alignments-for-vocabularies:
    desc: Suggest alignments for all vocabularies with GND data
    sources:
      - /data/ttl/main/vocabularies/*.ttl
    cmds:
      - for: sources
        task: _suggest-alignments
        vars:
          INPUT_FILE: "{{.ITEM}}"
          RECONCILIATION_TYPE: SubjectHeading
          BASE_TYPE: https://ontology.skkg.ch/Type
          LOG_FILE: /logs/suggest-alignments-for-vocabularies.log

  update-vocabularies:
    desc: Downloads, maps, and ingests the vocabularies
    cmds:
      - task: download-source-vocabularies
      - task: perform-mapping-for-vocabularies
      - sleep 5s
      - task: suggest-alignments-for-vocabularies
      - task: ingest-vocabularies
  
  validate-turtle-file:
    desc: Validate a Turtle file using SHACL. Pass the file to validate through command line argument
    cmds:
      - pyshacl -s /mapping/shapesGraph.ttl -e /mapping/schemas/skkg-ontology.ttl -e https://cidoc-crm.org/rdfs/7.1.1/CIDOC_CRM_v7.1.1.rdfs -m -i rdfs -a -j -f human {{.CLI_ARGS}}

  _download-vocabulary-from-museumplus:
    requires:
      vars: [VOCABULARY]
    vars:
      OUTPUT_FOLDER: /data/source/vocabularies
    cmds:
      - echo "Downloading {{.VOCABULARY}} vocabulary from MuseumPlus"
      - mkdir -p {{.OUTPUT_FOLDER}}
      - python /scripts/downloadVocabulary.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --vocabulary {{.VOCABULARY}} --outputFolder {{.OUTPUT_FOLDER}}

  _download-module-items-from-museumplus:
    requires:
      vars: [MODULE]
    vars:
      FOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
    cmds:
      - echo "Downloading {{.MODULE}} items from MuseumPlus"
      - mkdir -p {{.FOLDER}}
      - task: _download-items-from-museumplus
        vars:
          MODULE: "{{.MODULE}}"
          OUTPUT_FOLDER: "{{.FOLDER}}"
          FILENAMEPREFIX: "{{.FILENAMEPREFIX}}"

  _download-items-from-museumplus:
    requires:
      vars: [MODULE, OUTPUT_FOLDER, FILENAMEPREFIX]
    vars:
      TEMP_FOLDER: /data/temp/download/temp_{{.MODULE}}
    interactive: True
    cmds:
      - mkdir -p {{.TEMP_FOLDER}}
      - python /scripts/downloadItems.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --module {{.MODULE}} --outputFolder {{.OUTPUT_FOLDER}} --tempFolder {{.TEMP_FOLDER}} --filenamePrefix {{.FILENAMEPREFIX}} {{.CLI_ARGS}}

  _drop-graph:
    cmds:
      - curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null

  _generate-example-record:
    requires:
      vars: [OUTPUTFILE, INPUTFILES]
    vars:
      OUTPUTFILE: "{{.OUTPUTFILE}}"
      INPUTFILES: "{{.INPUTFILES}}"
    cmds:
      - cat {{.INPUTFILES}} > {{.OUTPUTFILE}}
      - sed -i 's/<application xmlns="http:\/\/www.zetcom.com\/ria\/ws\/module">//g' {{.OUTPUTFILE}}
      - sed -i 's/<modules>//g' {{.OUTPUTFILE}}
      - sed -i 's/<\/modules>//g' {{.OUTPUTFILE}}
      - sed -i 's/<\/application>//g' {{.OUTPUTFILE}}
      - echo '<application><modules>' | cat - {{.OUTPUTFILE}} > temp && mv temp {{.OUTPUTFILE}}; echo '</modules></application>' >> {{.OUTPUTFILE}}

  _ingest-data-from-file:
    vars:
      ENDPOINT: 
        sh: echo "{{if .ENDPOINT}}{{.ENDPOINT}}{{else}}{{.BLAZEGRAPH_ENDPOINT}}{{end}}"
    cmds:
      - echo "Ingest {{.NAME}}"
      - curl -X POST -H 'Content-Type:{{.TYPE}}' --data-binary '@{{.FILE}}' {{.ENDPOINT}}{{if .GRAPH}}?context-uri={{.GRAPH}}{{end}}

  _ingest_module_items:
    requires:
      vars: [MODULE, NAMESPACE]
    vars:
      INPUTFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      TEMPFOLDER:
        sh: echo "/data/temp/ingest/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      XMLFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
      DEBUG:
        sh: |
          # Your input string of arguments
          args="{{.CLI_ARGS}}"
          # Check if "--debug" is present in the input string
          if [[ "$args" == *"--debug"* ]]; then
            # Use parameter expansion to extract the value after "--debug"
            value="${args#*--debug }"
            # Split the arguments by space and get the first part as the value
            value="${value%% *}"
            echo "$value"
          else
            # "--debug" is not present, echo "false"
            echo "false"
          fi
    interactive: True
    cmds:
      - mkdir -p {{.TEMPFOLDER}}
      - |
        # If folder contains already ingested files we skip the preparation step
        if [ "$(find {{.TEMPFOLDER}} -type f -name '*.ttl.ingested' | wc -l)" -gt 0 ]; then
          echo "Skipping preparation step for {{.MODULE}} as there are already ingested files"
        else
          echo "Preparing {{.MODULE}} for ingest"
          python prepareDataForIngest.py  --inputFolder {{.INPUTFOLDER}} --outputFolder {{.TEMPFOLDER}} --xmlFolder {{.XMLFOLDER}}
        fi
      - |
        numfiles=$(find {{.TEMPFOLDER}} -type f -name '*.ttl' | wc -l)        
        count=1
        for f in $(find {{.TEMPFOLDER}} -type f -name '*.ttl' ); do
          identifier=$(basename "$f" | sed "s/{{.FILENAMEPREFIX}}//; s/\\.ttl//")
          graph="{{.NAMEDGRAPHBASE}}{{.FILENAMEPREFIX}}$identifier"
          echo "Ingesting {{.MODULE}} item $count of $numfiles into graph $graph"
          # Drop graph
          curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <$graph>" {{if eq .DEBUG "true"}}{{else}} > /dev/null{{end}}
          # Ingest into graph
          curl --silent -X POST --data-binary "uri=file://$f" "{{.BLAZEGRAPH_ENDPOINT}}?context-uri=$graph" {{if eq .DEBUG "true"}}{{else}} > /dev/null{{end}}
          count=$((count+1)) 
          mv $f $f.ingested
        done
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastIngested
          VALUE:
            sh: date -u "+%Y-%m-%d %H:%M:%S.000"
          SOURCEFOLDER: "{{.TEMPFOLDER}}"
          FILEEXTENSION: .ttl.ingested
      - find {{.TEMPFOLDER}} -maxdepth 1 -name "*.ttl.ingested" -delete
  
  _ingest_vocabularies:
    requires:
      vars: [INPUTFOLDER, NAMESPACE]
    vars:
      NAMESPACE: "{{.NAMESPACE}}"
    cmds:
      - echo "Ingesting vocabularies"
      - |
        numfiles=$(find {{.INPUTFOLDER}} -type f -name '*.ttl' | wc -l)
        count=1
        for f in $(find {{.INPUTFOLDER}} -type f -name '*.ttl' ); do
          uri=$(grep -oPm 1 '(<{{.NAMESPACE}})[0-9]+>' $f) 
          # Strip < and > at beginning and end of uri
          graph=${uri:1:-1}
          echo -e "Ingesting vocabulary $graph ($count of $numfiles)"
          # Drop graph
          curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <$graph>" > /dev/null
          # Ingest vocabulary into graph
          curl --silent -X POST --data-binary "uri=file://$f" "{{.BLAZEGRAPH_ENDPOINT}}?context-uri=$graph"
          count=$((count+1)) 
        done

  _perform-mapping-for-module-items:
    requires:
      vars: [MODULE]
    vars:
      INPUTFOLDER:
        sh: echo "/mapping/input/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      OUTPUTFOLDER:
        sh: echo "/mapping/output/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      DESTINATIONFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      MAPPINGFILE:
        sh: echo "/mapping/mapping-$(echo "{{.MODULE}}" | awk '{print tolower($0)}').x3ml"
    cmds:
      - mkdir -p {{.OUTPUTFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -delete
      - bash /scripts/performMapping.sh -i {{.INPUTFOLDER}} -o {{.OUTPUTFOLDER}} -m {{.MAPPINGFILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}
      - sleep 5s # Wait for the mapping to finish
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastMapped
          VALUE:
            sh: date -u "+%Y-%m-%d %H:%M:%S.000"
          SOURCEFOLDER: "{{.INPUTFOLDER}}"
          FILEEXTENSION: .xml
      - task: _perform-post-mapping-tasks
        vars:
          MODULE: "{{.MODULE}}"
          FOLDER: "{{.OUTPUTFOLDER}}"
      - mkdir -p {{.DESTINATIONFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -exec mv -t {{.DESTINATIONFOLDER}} {} +

  _perform-post-mapping-tasks:
    requires:
      vars: [MODULE, FOLDER]
    cmds:
      - echo "Performing post-mapping tasks for {{.MODULE}}"
      - task: _validate-turtle-files-in-folder
        vars:
          FOLDER: "{{.FOLDER}}"

  _prepare-mapping-for-module-items:
    requires:
      vars: [MODULE]
    vars:
      MODULE: "{{.MODULE}}"
      INPUTFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      OUTPUTFOLDER:
        sh: echo "/mapping/input/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - # TODO: separate preparation script (e.g. enrichment of data) from mapping preparation (i.e. moving relevant xml files to a place where they should be mapped)
      - mkdir -p {{.OUTPUTFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.xml" -delete
      - python /scripts/prepareDataForMapping.py --module {{.MODULE}} --inputFolder {{.INPUTFOLDER}} --outputFolder {{.OUTPUTFOLDER}} {{.CLI_ARGS}}

  _process-items-deleted-from-museumplus:
    vars: 
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
    interactive: True
    cmds:
      - python /scripts/processDeletedItems.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --module {{.MODULE}} --inputFolder {{.INPUT_FOLDER}} --namedGraphBase {{.NAMEDGRAPHBASE}} --filenamePrefix {{.FILENAMEPREFIX}} --sparqlEndpoint {{.BLAZEGRAPH_ENDPOINT}}

  _remove-deleted-module-items:
    requires:
      vars: [MODULE]
    vars:
      FOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
    cmds:
      - echo "Checking for deleted items in {{.MODULE}}"
      - task: _process-items-deleted-from-museumplus
        vars:
          MODULE: "{{.MODULE}}"
          INPUT_FOLDER: "{{.FOLDER}}"
          FILENAMEPREFIX: "{{.FILENAMEPREFIX}}"

  _suggest-alignments:
    interactive: True
    requires:
      vars: [INPUT_FILE, RECONCILIATION_TYPE, BASE_TYPE, RECONCILIATION_TYPE]
    vars:
      LIMIT: 5
      OUTPUTFILE:
        sh: echo "/data/ttl/additional/classifications/$(basename {{.INPUT_FILE}} .ttl)-alignments.ttl"
    cmds:
        - python /scripts/suggestAlignments.py --input_file "{{.INPUT_FILE}}" --reconciliation_type "{{.RECONCILIATION_TYPE}}"  --limit "{{.LIMIT}}" --output_file "{{.OUTPUTFILE}}" --base_type "{{.BASE_TYPE}}" {{if .LOG_FILE}}--log_file "{{.LOG_FILE}}"{{end}}

  _update-metadata-for-module:
    requires:
      vars: [MODULE, KEY, VALUE, SOURCEFOLDER, FILEEXTENSION]
    vars:
      METADATAFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      SOURCEFOLDER: "{{.SOURCEFOLDER}}"
      KEY: "{{.KEY}}"
      VALUE: "{{.VALUE}}"
      FILEEXTENSION: "{{.FILEEXTENSION}}"
    cmds:
      - python /scripts/updateMetadataValueForFiles.py --metadataFolder {{.METADATAFOLDER}} --inputFolder {{.SOURCEFOLDER}} --key {{.KEY}} --value "{{.VALUE}}" --fileExtension {{.FILEEXTENSION}}

  _validate-turtle-files-in-folder:
    requires:
      vars: [FOLDER]
    vars:
      SHAPES_GRAPH: /mapping/shapesGraph.ttl
      SCHEMA_SKKG: /mapping/schemas/skkg-ontology.ttl
      REPORTS_GRAPH: "{{.NAMESPACE}}graph/shaclReports"
      LIMIT: 100
    interactive: True
    cmds:
      - python /scripts/validateTurtleWithShacl.py --directory "{{.FOLDER}}" --shapesGraph {{.SHAPES_GRAPH}} --ontologyFile {{.SCHEMA_SKKG}} --endpoint {{.BLAZEGRAPH_ENDPOINT}} --namedGraph {{.REPORTS_GRAPH}} --limit {{.LIMIT}} {{if .DEBUG}}--debug{{end}}