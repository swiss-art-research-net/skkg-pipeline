# https://taskfile.dev

version: '3'

vars:
  # Customisable variables
  MODULES: Address,Exhibition,Literature,Multimedia,Object,ObjectGroup,Person,Ownership,Registrar
  NAMESPACE: https://data.skkg.ch/
  # Presets
  BLAZEGRAPH_BACKUP: http://blazegraph:8080/blazegraph/backup
  BLAZEGRAPH_ENDPOINT: http://blazegraph:8080/blazegraph/sparql
  BLAZEGRAPH_ENDPOINT_SECONDARY: http://blazegraph-secondary:8080/blazegraph/sparql
  GENERATOR_POLICY: /mapping/generator-policy.xml
  X3ML_ENDPOINT: http://localhost:8089/transform

output: 'prefixed'

includes:
  dev:
    taskfile: ./taskfiles/dev.yml
    flatten: true
  internal:
    taskfile: ./taskfiles/internal.yml
    flatten: true
  logging:
    taskfile: ./taskfiles/logging.yml
    flatten: true
    aliases: [log]
  utilities:
    taskfile: ./taskfiles/utilities.yml
    flatten: true

tasks:

  default:
    desc: Runs the entire pipeline
    cmds:
      - '[ $(pgrep -cx "task") -gt 1 ] && echo "Another task is currently being executed. Wait for it to complete before running the pipeline." && exit 1 || echo "Running pipeline..." && exit 0'
      - task: download-source-items
      - task: prepare-and-perform-mapping-for-items
      - task: ingest-items
      - task: ingest-classifications
      - task: ingest-ontologies
      - task: ingest-alignments
      - task: retrieve-and-ingest-additional-data

  create-blazegraph-backup:
    desc: Creates a compressed Blazegraph backup
    vars:
      FILENAME:
        sh: echo "/backup/blazegraph-$(date "+%Y-%m-%d-%H-%M-%S").jnl.gz"
    cmds:
       - curl --data-urlencode "file={{.FILENAME}}" --data-urlencode "compress=true" --data-urlencode "block=true" {{.BLAZEGRAPH_BACKUP}}  
      
  download-source-items:
    desc: Downloads all item records from MuseumPlus
    cmds:
      - for:
          var: MODULES
          split: ','
          as: MODULE
        task: _download-module-items-from-museumplus
        vars:
          MODULE: "{{.MODULE}}"

  download-source-vocabularies:
    desc: Downloads all vocabularies from MuseumPlus
    cmds:
      - for:
          - AdrCountryVgr
          - AdrTypeVgr
          - ExhExternalInternalVgr
          - ExhOrganiserTypeVgr
          - ExhTypeVgr
          - ExhStatusVgr
          - GenCurrencyVgr
          - GenLanguageVgr
          - GenMoveStatusVgr
          - LitAuthorTypeVgr
          - LitLanguageVgr
          - LitTypeVgr
          - LitPlaceVgr
          - LitPersonTypeVgr
          - MulCategoryVgr
          - MulRightsTypeVgr
          - MulUsageVgr
          - MulTypeVgr
          - ObjAcquisitionModeVgr
          - ObjCategoryVgr
          - ObjConditionShortVgr
          - ObjDatePeriodVgr
          - ObjDatePrefixVgr
          - ObjDateSourceVgr
          - ObjDateSuffixVgr
          - ObjDateTypeVgr
          - ObjDim3DTypeVgr
          - ObjDocumentationStatusVgr
          - ObjIconographyVgr
          - ObjIconographyTypeVgr
          - ObjInscriptionDialogTypeVgr
          - ObjInscriptionTypeVgr
          - ObjInscriptionPositionVgr
          - ObjMaterialVgr
          - ObjMaterialTechniqueVgr
          - ObjMaterialTechniqueTypeVgr
          - ObjObjectTitleTypeVgr
          - ObjObjectTitleSourceVgr
          - ObjObjectTypeVgr
          - ObjOtherNumberTypeVgr
          - ObjPerAssociationRoleVgr
          - ObjPerAssociationAttributionVgr
          - ObjTechniqueVgr
          - ObjTextsTypeVgr
          - OwsAcquisitionTypeVgr
          - OwsArtPersonVgr
          - OwsCharacteristicsTypeVgr
          - OwsOwnerTypeVgr
          - OwsEvidenceVgr
          - OwsSourcesOtherTypeVgr
          - OwsPrefixTypVgr
          - OwsRelevanceSourceVgr
          - PerDateTypeVgr
          - PerGenderVgr
          - PerPersonTypeVgr
          - PerTypeVgr
        task: _download-vocabulary-from-museumplus
        vars:
          VOCABULARY: "{{.ITEM}}"
          
  download-items-for-module:
    desc: Downloads the item records for a specific module from MuseumPlus. Pass the module name as command line argument
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
    cmds:
      - task: _download-module-items-from-museumplus
        vars:
          MODULE: "{{.MODULE}}"

  first-run:
    desc: Task to run when the pipeline is run for the first time
    cmds:
      - task: update-vocabularies
      - task: update-iiif 
      - task: ingest-platform-data
 
  ingest-alignments:
    desc: Ingests the alignments into the triplestore
    sources:
      - /data/ttl/additional/alignments/*.ttl
    cmds:
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME:
            sh: echo "$(basename {{.ITEM}} .ttl)"
          FILE: "{{.ITEM}}"
          TYPE: application/x-turtle
          GRAPH: 
            sh: echo "{{.NAMESPACE}}graph/alignments/$(basename {{.ITEM}} .ttl)"
          ENDPOINT: "{{.BLAZEGRAPH_ENDPOINT}}"

  ingest-classifications:
    desc: Ingest classifications into the triplestore
    sources:
      - /data/ttl/additional/classifications/*.ttl
    cmds:
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME:
            sh: echo "$(basename {{.ITEM}} .ttl)"
          FILE: "{{.ITEM}}"
          TYPE: application/x-turtle
          GRAPH: 
            sh: echo "{{.NAMESPACE}}graph/classifications/$(basename {{.ITEM}} .ttl)"
          ENDPOINT: "{{.BLAZEGRAPH_ENDPOINT_SECONDARY}}"
  
  ingest-items:
    desc: Ingest items for all modules. Add --debug true To see the response from the triplestore
    cmds:
      - for:
          var: MODULES
          split: ','
          as: MODULE
        task: _ingest_module_items
        vars:
          MODULE: "{{.MODULE}}"

  ingest-iiif:
    desc: Ingest IIIF data into the triplestore
    sources:
      - /data/ttl/main/iiif/*.ttl
    cmds:
      - for: sources
        task: _drop-graph
        vars:
          GRAPH:
            sh: echo "{{.NAMESPACE}}graph/iiif/$(basename {{.ITEM}} .ttl)"
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME:
            sh: echo "$(basename {{.ITEM}} .ttl)"
          FILE: "{{.ITEM}}"
          TYPE: application/x-turtle
          GRAPH: 
            sh: echo "{{.NAMESPACE}}graph/iiif/$(basename {{.ITEM}} .ttl)"
          ENDPOINT: "{{.BLAZEGRAPH_ENDPOINT}}"

  ingest-module-items:
    desc: Ingests the items for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) substr($0,2)}')"
    cmds:
      - task: _ingest_module_items
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"
          DEBUG: true
  
  ingest-ontologies:
    desc: Ingests the ontologies into individual named Graphs
    sources:
      - /mapping/schemas/*.*
    cmds:
      - task: _ingest-data-from-file
        vars:
          NAME: CIDOC-CRM
          FILE: /mapping/schemas/CIDOC_CRM_7.1.1_RDFS_Impl_v1.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/cidoc-crm
      - task: _ingest-data-from-file
        vars:
          NAME: CIDOC-CRM PC
          FILE: /mapping/schemas/CIDOC_CRM_v7.1.3_PC.rdf
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/cidoc-crm/pc
      - task: _ingest-data-from-file
        vars:
          NAME: CRMdig
          FILE: /mapping/schemas/CRMdig_v3.2.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.ics.forth.gr/isl/CRMdig
      - task: _ingest-data-from-file
        vars:
          NAME: CRMsci
          FILE: /mapping/schemas/CRMsci_v2.0.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/extensions/crmsci
      - task: _ingest-data-from-file
        vars:
          NAME: FRBRoo
          FILE: /mapping/schemas/FRBR2.4.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://iflastandards.info/ns/fr/frbr/frbroo
      - task: _ingest-data-from-file
        vars:
          NAME: Linked.Art
          FILE: /mapping/schemas/LinkedArt.rdfs
          TYPE: application/rdf+xml
          GRAPH: https://linked.art/ns/terms
      - task: _ingest-data-from-file
        vars:
          NAME: aaao
          FILE: /mapping/schemas/aaao.rdfs
          TYPE: application/rdf+xml
          GRAPH: https://ontology.swissartresearch.net/aaao/
      - task: _ingest-data-from-file
        vars:
          NAME: ResearchSpace Ontology
          FILE: /mapping/schemas/rs-ontology.ttl
          TYPE: application/x-turtle
          GRAPH: http://www.researchspace.org/ontology
      - task: _ingest-data-from-file
        vars:
          NAME: SKKG Ontology
          FILE: /mapping/schemas/skkg-ontology.ttl
          TYPE: application/x-turtle
          GRAPH: http://ontology.skkg.ch/ontology

  ingest-platform-data:
    desc: Ingests the data used for the operation of the platform
    sources:
      - /data/platform/*.trig
    cmds: 
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME: "{{.ITEM}}"
          FILE: "{{.ITEM}}"
          TYPE: application/x-trig

  ingest-vocabularies:
    - task: _ingest_vocabularies
      vars:
        INPUTFOLDER: /data/ttl/main/vocabularies
        NAMESPACE: https://data.skkg.ch/type/

  perform-mapping-for-module-items:
    desc: Performs the mapping for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) substr($0,2)}')"
    cmds:
      - task: _perform-mapping-for-module-items
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  prepare-and-perform-mapping-for-items:
    desc: Prepares and performs the mapping for all modules
    cmds:
      - echo "Preparing mapping..."
      - for:
          - Address
          - Exhibition
          - Literature
          - Multimedia
          - Object
          - ObjectGroup
          - Person
          - Ownership
          - Registrar
        task: _prepare-mapping-for-module-items
        vars:
          MODULE: "{{.ITEM}}"
      - echo "Mapping..."
      - for:
          - Address
          - Exhibition
          - Literature
          - Multimedia
          - Object
          - ObjectGroup
          - Person
          - Ownership
        task: _perform-mapping-for-module-items
        vars:
          MODULE: "{{.ITEM}}"

  prepare-mapping-for-module-items:
    desc: Prepares the mapping for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) substr($0,2)}')"
    cmds:
      - task: _prepare-mapping-for-module-items
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"
    
  prepare-and-perform-mapping-for-iiif:
    desc: Performs the mapping for the IIIF data
    sources:
      - /mapping/mapping-iiif.x3ml
      - /data/source/iiif/*.xml
    vars:
      SOURCEFOLDER: /data/source/iiif
      INPUTFOLDER: /mapping/input/iiif
      OUTPUTFOLDER: /data/ttl/main/iiif
      MAPPINGFILE: /mapping/mapping-iiif.x3ml
    cmds:
      - mkdir -p {{.INPUTFOLDER}}
      - mkdir -p {{.OUTPUTFOLDER}}
      - rm -rf {{.INPUTFOLDER}}/*.xml
      - rm -rf {{.OUTPUTFOLDER}}/*.ttl
      - # Copy all XML files from the source folder to the input folder
      - find {{.SOURCEFOLDER}} -maxdepth 1 -name "*.xml" -exec cp -t {{.INPUTFOLDER}} {} +
      - bash /scripts/performMapping.sh -i {{.INPUTFOLDER}} -o {{.OUTPUTFOLDER}} -m {{.MAPPINGFILE}} -g {{.GENERATOR_POLICY}} -j {{.X3ML_ENDPOINT}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -exec cat {} + > {{.OUTPUTFOLDER}}/iiifPaths.ttl.temp
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -delete
      - mv {{.OUTPUTFOLDER}}/iiifPaths.ttl.temp {{.OUTPUTFOLDER}}/iiifPaths.ttl
      - task: _clean_turtle_file_from_extra_prefixes
        vars:
          FILE: "{{.OUTPUTFOLDER}}/iiifPaths.ttl"

  perform-mapping-for-vocabularies:
    desc: Performs the mapping for the vocabularies
    sources:
      - /mapping/mapping-vocabulary.x3ml
      - /data/source/vocabularies/*.xml
    vars:
      SOURCEFOLDER: "/data/source/vocabularies"
      INPUTFOLDER: "/mapping/input/vocabularies"
      OUTPUTFOLDER: "/data/ttl/main/vocabularies"
      MAPPINGFILE: "/mapping/mapping-vocabulary.x3ml"
    cmds:
      - mkdir -p {{.INPUTFOLDER}}
      - mkdir -p {{.OUTPUTFOLDER}}
      - # Copy all XML files from the source folder to the input folder
      - find {{.SOURCEFOLDER}} -maxdepth 1 -name "*.xml" -exec cp -t {{.INPUTFOLDER}} {} +
      - # Remove the string 'xmlns="http://www.zetcom.com/ria/ws/vocabulary"' from the XML files in the input folder as X3ML is not able to handle XML namespaces
      - find {{.INPUTFOLDER}} -maxdepth 1 -name "*.xml" -exec sed -i 's/xmlns="http:\/\/www.zetcom.com\/ria\/ws\/vocabulary"//g' {} +
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -delete
      - bash /scripts/performMapping.sh -i {{.INPUTFOLDER}} -o {{.OUTPUTFOLDER}} -m {{.MAPPINGFILE}} -g {{.GENERATOR_POLICY}}  -j {{.X3ML_ENDPOINT}}
  
  recreate-folder-metadata:
    desc: Recreate the metadata for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
    cmds:
      - rm -f /data/source/{{.MODULE}}/metadata.json
      - python /scripts/recreateMetadata.py --folder /data/source/{{.MODULE}}

  remove-unpublished-module-items:
    desc: Removes item records that have been unpublished from MuseumPlus for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST: 
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) substr($0,2)}')"
    cmds:
      - echo "Removing unpublished {{.MODULE}} items..."
      - task: _remove-unpublished-module-items
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  remove-unpublished-items:
    desc: Removes all item records that have been unpublished from MuseumPlus. Note that Multimedia items are skipped and should be processed separately if needed.
    cmds:
      - for:
          - Address
          - Exhibition
          - Literature
          - Object
          - ObjectGroup
          - Person
          - Registrar
          - Ownership
        task: _remove-unpublished-module-items
        vars:
          MODULE: "{{.ITEM}}"

  remove-module-items-from-triplestore:
    desc: Removes all item records for a specific module from the triplestore. The module name should be passed as an argument or via the MODULE variable.
    prompt: This will remove all item records for the module {{.MODULE_UCFIRST}} from the triplestore. Do you want to continue?
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) substr($0,2)}')"
    cmds:
      - task: _remove-module-items-from-triplestore
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"
      - task: reset-last-ingested-metadata
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  remove-items-without-equivalent-ttl-from-triplestore:
    desc: Removes all item records from the triplestore that do not have an equivalent TTL file. Note that Multimedia items are skipped and should be processed separately if needed.
    cmds:
      - for:
          - Address
          - Exhibition
          - Literature
          - Object
          - ObjectGroup
          - Person
          - Registrar
          - Ownership
        task: _remove-module-items-without-equivalent-ttl-from-triplestore
        vars:
          MODULE: "{{.ITEM}}"

  remove-module-items-without-equivalent-ttl-from-triplestore:
    desc: Removes all item records for a specific module from the triplestore that do not have an equivalent TTL file. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) substr($0,2)}')"
    cmds:
      - task: _remove-module-items-without-equivalent-ttl-from-triplestore
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  retrieve-and-ingest-additional-data:
    desc: Retrieve and ingest additional data for external URIs in the Triple Store 
    interactive: True
    vars:
      OUTPUTFOLDER: /data/ttl/additional/external
      PREDICATES: http://www.ics.forth.gr/isl/CRMdig/L54_is_same-as,http://www.cidoc-crm.org/cidoc-crm/P2_has_type,http://www.cidoc-crm.org/cidoc-crm/P127_has_broader_term,http://www.w3.org/2004/02/skos/core#exactMatch,http://www.w3.org/2004/02/skos/core#closeMatch,http://www.w3.org/2004/02/skos/core#relatedMatch,http://www.w3.org/2004/02/skos/core#related
      SOURCES: gnd,aat,lt
      INGEST: True
      INGESTUPDATE: True
      INGESTNAMESPACE: https://data.skkg.ch/graph/externalData/
    cmds:
      - python /scripts/retrieveAdditionalData.py --endpoint {{.BLAZEGRAPH_ENDPOINT}} --outputFolder {{.OUTPUTFOLDER}} --predicates "{{.PREDICATES}}" --ingest {{.INGEST}} --ingestNamespace {{.INGESTNAMESPACE}} --ingestUpdate {{.INGESTUPDATE}} --sources "{{.SOURCES}}"
      - for:
          - gnd
          - aat
          - lt
        task: _clean_turtle_file_from_extra_prefixes
        vars:
          FILE: "/data/ttl/additional/external/{{.ITEM}}.ttl"

  retrieve-iiif-data:
    desc: Downloads and prepares data related to the IIIF images
    vars:
      OUTPUTFOLDER: /data/source/iiif
    cmds:
      - mkdir -p {{.OUTPUTFOLDER}}
      - python /scripts/retrieveIiifData.py --input $IIIF_CSV_URL --outputFolder {{.OUTPUTFOLDER}} --filename iiifPaths
 
  reset:
    desc: Delete all artefacts produced by the pipeline.
    prompt: This will delete all artefacts produced by the pipeline... Do you want to continue?
    cmds:
      - rm -f /scripts/.task/checksum/*
      - for:
          - Address
          - Exhibition
          - Literature
          - Multimedia
          - Object
          - ObjectGroup
          - Person
          - Registrar
          - Ownership
        task: reset-module
        vars:
          MODULE: "{{.ITEM}}"
      - task: _reset-iiif-and-vocabularies
      - echo "Done!"

  reset-iiif:
    desc: Delete all artefacts produced by the pipeline for the iiif data.
    cmds: 
      - rm -rf /data/ttl/main/iiif
      - rm -rf /mapping/input/iiif
      - rm -rf /mapping/output/iiif

  reset-module:
    desc: Delete all artefacts produced by the pipeline for a given module. The module name should be passed as an argument or via the MODULE variable.
    silent: true
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_LOWERCASE:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) substr($0,2)}')"
    cmds:
      - |
        if [ -z "{{.MODULE}}" ]; then
          echo "No module specified as variable or cli argument. Exiting script."
          exit 1
        fi
      - echo "Deleting files for {{.MODULE}}..."
      - rm -rf /data/temp/download/temp_{{.MODULE_UCFIRST}}
      - rm -rf /data/temp/ingest/{{.MODULE_LOWERCASE}}
      - rm -rf /data/ttl/main/{{.MODULE_LOWERCASE}}
      - rm -rf /mapping/input/{{.MODULE_LOWERCASE}}
      - rm -rf /mapping/output/{{.MODULE_LOWERCASE}}
      - echo "Resetting metadata for {{.MODULE}}.."
      - task: recreate-folder-metadata
        vars:
          MODULE: "{{.MODULE_LOWERCASE}}"

  reset-vocabularies:
    desc: Delete all artefacts produced by the pipeline for the vocabularies.
    cmds: 
      - rm -rf /data/ttl/main/vocabularies
      - rm -rf /mapping/input/vocabularies
      - rm -rf /mapping/output/vocabularies

  reset-last-ingested-metadata:
    desc: Resets the last ingested metadata for a specific module. Pass the module name as an argument and optionally a new date (YYYY-MM-DD).
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "$(echo "{{.CLI_ARGS}}" | awk '{print $1}')"
          else
            echo "{{.MODULE}}"
          fi
      DATE:
        sh: |
          ARG_DATE=$(echo "{{.CLI_ARGS}}" | awk '{print $2}')
          if [ -z "$ARG_DATE" ]; then
            echo "1970-01-01 00:00:00.000"
          else
            echo "$ARG_DATE 00:00:00.000"
          fi
      SOURCEFOLDER:
        sh: |
          echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastIngested
          VALUE: "{{.DATE}}"
          SOURCEFOLDER: "{{.SOURCEFOLDER}}"
          FILEEXTENSION: .xml

  reset-last-mapped-metadata:
    desc: Resets the last mapped metadata for a specific module. Pass the module name as an argument and optionally a new date (YYYY-MM-DD).
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "$(echo "{{.CLI_ARGS}}" | awk '{print $1}')"
          else
            echo "{{.MODULE}}"
          fi
      DATE:
        sh: |
          ARG_DATE=$(echo "{{.CLI_ARGS}}" | awk '{print $2}')
          if [ -z "$ARG_DATE" ]; then
            echo "1970-01-01 00:00:00.000"
          else
            echo "$ARG_DATE 00:00:00.000"
          fi
      SOURCEFOLDER:
        sh: |
          echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastMapped
          VALUE: "{{.DATE}}"
          SOURCEFOLDER: "{{.SOURCEFOLDER}}"
          FILEEXTENSION: .xml
  
  suggest-alignments-for-vocabularies:
    desc: Suggest alignments for all vocabularies with GND data
    sources:
      - /data/ttl/main/vocabularies/*.ttl
    cmds:
      - for: sources
        task: _suggest-alignments
        vars:
          INPUT_FILE: "{{.ITEM}}"
          RECONCILIATION_TYPE: SubjectHeading
          BASE_TYPE: https://ontology.skkg.ch/Type
          LOG_FILE: /logs/suggest-alignments-for-vocabularies.log

  update-iiif:
    desc: Downloads, maps, and ingests the IIIF data
    cmds: 
      - task: retrieve-iiif-data
      - task: prepare-and-perform-mapping-for-iiif
      - task: ingest-iiif

  update-vocabularies:
    desc: Downloads, maps, and ingests the vocabularies
    cmds:
      - task: download-source-vocabularies
      - task: perform-mapping-for-vocabularies
      - sleep 5s
      - task: suggest-alignments-for-vocabularies
      - task: ingest-vocabularies
  
  validate-turtle-file:
    desc: Validate a Turtle file using SHACL. Pass the file to validate through command line argument
    cmds:
      - pyshacl -s /mapping/shapesGraph.ttl -e /mapping/schemas/skkg-ontology.ttl -e https://cidoc-crm.org/rdfs/7.1.1/CIDOC_CRM_v7.1.1.rdfs -m -i rdfs -a -j -f turtle {{.CLI_ARGS}}

  _combine_and_ingest_shacl_reports:
    internal: true
    requires:
      vars: [TEMP_FOLDER, REPORTS_GRAPH, REPORT_IRI]
    status:
      - '[ "$(find {{.TEMP_FOLDER}} -name "*.ttl" -type f)" ] || exit 0 && exit 1'
    vars:
      ENDPOINT: "{{.BLAZEGRAPH_ENDPOINT_SECONDARY}}"
    cmds:
      # Combine the failed tests into a single N-Triples file. We use N-Triples so we have a single line per triple
      - rm -f {{.TEMP_FOLDER}}/validation_output.nt
      - |
        find {{.TEMP_FOLDER}} -name '*.ttl' -exec sh -c '
          filename=$(basename "{}" .ttl)
          rapper -q -i turtle -o ntriples "{}" | sed "s/_:genid/_:genid_${filename}_/g" >> {{.TEMP_FOLDER}}/validation_output.nt
        ' \;
      - find {{.TEMP_FOLDER}} -type f -name '*.ttl' -delete
      # Replace the blank nodes with named nodes based on the filename. We add a validation: prefix
      - sed -e "s/_:genid_validate-/validation:/g" {{.TEMP_FOLDER}}/validation_output.nt > {{.TEMP_FOLDER}}/validation_output_temp.ttl
      # Add the PREFIX line to the top of the file
      - 'echo "@prefix validation: <http://data.skkg.ch/validation/> ." | cat - {{.TEMP_FOLDER}}/validation_output_temp.ttl > {{.TEMP_FOLDER}}/validation_output.ttl'
      # Remove in-between files
      - rm -f {{.TEMP_FOLDER}}/validation_output_temp.ttl
      - rm -f {{.TEMP_FOLDER}}/validation_output.nt
      # Combine individual reports into a single report by extracting the IRI of the report and replacing it with a single IRI
      - grep '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/ns/shacl#ValidationReport>' "{{.TEMP_FOLDER}}/validation_output.ttl" | awk '{print $1}' > {{.TEMP_FOLDER}}/iri_list.txt
      - cat "{{.TEMP_FOLDER}}/iri_list.txt"
      - |
        for iri in $(cat "{{.TEMP_FOLDER}}/iri_list.txt"); do
          sed -i "s|$iri|{{.REPORT_IRI}}|g" "{{.TEMP_FOLDER}}/validation_output.ttl"
        done
      - rm {{.TEMP_FOLDER}}/iri_list.txt
      - echo "{{.REPORT_IRI}} <http://www.w3.org/ns/prov#endedAtTime> \"$(date "+%Y-%m-%dT%H:%M:%S")\"^^<http://www.w3.org/2001/XMLSchema#dateTime> ." >> {{.TEMP_FOLDER}}/validation_output.ttl
      # Add a rdfs:label based on the source folder
      - echo "{{.REPORT_IRI}} <http://www.w3.org/2000/01/rdf-schema#label> \"Validation report {{.REPORT_SOURCEFOLDER}}\" ." >> {{.TEMP_FOLDER}}/validation_output.ttl
      # Ingest to graph 
      - "curl -X POST -H 'Content-Type: application/x-turtle'  --data-binary @{{.TEMP_FOLDER}}/validation_output.ttl {{.ENDPOINT}}?context-uri={{.REPORTS_GRAPH}}"
      - rm -f {{.TEMP_FOLDER}}/validation_output.ttl
      
  _download-vocabulary-from-museumplus:
    internal: true
    requires:
      vars: [VOCABULARY]
    vars:
      OUTPUT_FOLDER: /data/source/vocabularies
    cmds:
      - echo "Downloading {{.VOCABULARY}} vocabulary from MuseumPlus"
      - mkdir -p {{.OUTPUT_FOLDER}}
      - python /scripts/downloadVocabulary.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --vocabulary {{.VOCABULARY}} --outputFolder {{.OUTPUT_FOLDER}}

  _download-module-items-from-museumplus:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      FOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) substr($0,2)}')"
    cmds:
      - echo "Downloading {{.MODULE_UCFIRST}} items from MuseumPlus"
      - mkdir -p {{.FOLDER}}
      - task: _download-items-from-museumplus
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"
          OUTPUT_FOLDER: "{{.FOLDER}}"
          FILENAMEPREFIX: "{{.FILENAMEPREFIX}}"

  _download-items-from-museumplus:
    internal: true
    requires:
      vars: [MODULE, OUTPUT_FOLDER, FILENAMEPREFIX]
    vars:
      TEMP_FOLDER: /data/temp/download/temp_{{.MODULE}}
    interactive: True
    cmds:
      - mkdir -p {{.TEMP_FOLDER}}
      - python /scripts/downloadItems.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --module {{.MODULE}} --outputFolder {{.OUTPUT_FOLDER}} --tempFolder {{.TEMP_FOLDER}} --filenamePrefix {{.FILENAMEPREFIX}} {{.CLI_ARGS}}

  _drop-graph:
    internal: true
    cmds:
      - curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null

  _ingest-data-from-file:
    internal: true
    vars:
      ENDPOINT: 
        sh: echo "{{if .ENDPOINT}}{{.ENDPOINT}}{{else}}{{.BLAZEGRAPH_ENDPOINT}}{{end}}"
    cmds:
      - echo "Ingest {{.NAME}}"
      - curl --silent -X POST {{.ENDPOINT}} --data-urlencode 'update={{if .GRAPH}}DROP GRAPH <{{.GRAPH}}>{{end}}'
      - curl -X POST -H 'Content-Type:{{.TYPE}}' --data-binary '@{{.FILE}}' {{.ENDPOINT}}{{if .GRAPH}}?context-uri={{.GRAPH}}{{end}}

  _ingest_module_items:
    internal: true
    requires:
      vars: [MODULE, NAMESPACE]
    vars:
      INPUTFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      TEMPFOLDER:
        sh: echo "/data/temp/ingest/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      XMLFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
      DEBUG:
        sh: |
          # Your input string of arguments
          args="{{.CLI_ARGS}}"
          # Check if "--debug" is present in the input string
          if [[ "$args" == *"--debug"* ]]; then
            # Use parameter expansion to extract the value after "--debug"
            value="${args#*--debug }"
            # Split the arguments by space and get the first part as the value
            value="${value%% *}"
            echo "$value"
          else
            if [ -z "{{.DEBUG}}" ]; then
              echo "false"
            else
              echo "{{.DEBUG}}"
            fi
          fi
    interactive: True
    cmds:
      - mkdir -p {{.TEMPFOLDER}}
      - |
        # If folder contains already ingested files we skip the preparation step
        if [ "$(find {{.TEMPFOLDER}} -type f -name '*.ttl.ingested' | wc -l)" -gt 0 ]; then
          echo "Skipping preparation step for {{.MODULE}} as there are already ingested files"
        else
          echo "Preparing {{.MODULE}} for ingest"
          python prepareDataForIngest.py  --inputFolder {{.INPUTFOLDER}} --outputFolder {{.TEMPFOLDER}} --xmlFolder {{.XMLFOLDER}}
        fi
      - |
        numfiles=$(find {{.TEMPFOLDER}} -type f -name '*.ttl' | wc -l)        
        count=1
        for f in $(find {{.TEMPFOLDER}} -type f -name '*.ttl' ); do
          identifier=$(basename "$f" | sed "s/{{.FILENAMEPREFIX}}//; s/\\.ttl//")
          graph="{{.NAMEDGRAPHBASE}}{{.FILENAMEPREFIX}}$identifier"
          echo "Ingesting {{.MODULE}} item $count of $numfiles into graph $graph"
          # Drop graph
          curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <$graph>" {{if eq .DEBUG "true"}}{{else}} > /dev/null{{end}}
          # Ingest into graph
          curl --silent -X POST --data-binary "uri=file://$f" "{{.BLAZEGRAPH_ENDPOINT}}?context-uri=$graph" {{if eq .DEBUG "true"}}{{else}} > /dev/null{{end}}
          count=$((count+1)) 
          mv $f $f.ingested
        done
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastIngested
          VALUE:
            sh: date "+%Y-%m-%d %H:%M:%S.000"
          SOURCEFOLDER: "{{.TEMPFOLDER}}"
          FILEEXTENSION: .ttl.ingested
      - find {{.TEMPFOLDER}} -maxdepth 1 -name "*.ttl.ingested" -delete
  
  _ingest_vocabularies:
    internal: true
    requires:
      vars: [INPUTFOLDER, NAMESPACE]
    vars:
      NAMESPACE: "{{.NAMESPACE}}"
    cmds:
      - echo "Ingesting vocabularies"
      - |
        numfiles=$(find {{.INPUTFOLDER}} -type f -name '*.ttl' | wc -l)
        count=1
        for f in $(find {{.INPUTFOLDER}} -type f -name '*.ttl' ); do
          uri=$(grep -oPm 1 '(<{{.NAMESPACE}})[0-9]+' $f) 
          # Strip < at beginning and end of uri
            graph=${uri:1}
          echo -e "Ingesting vocabulary $graph ($count of $numfiles)"
          # Drop graph
          curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <$graph>" > /dev/null
          # Ingest vocabulary into graph
          curl --silent -X POST --data-binary "uri=file://$f" "{{.BLAZEGRAPH_ENDPOINT}}?context-uri=$graph"
          count=$((count+1)) 
        done

  _output_message:
    internal: true
    decs: Output a message to the console
    silent: true
    requires:
      vars: [MESSAGE]
    cmds:
      - echo "{{.MESSAGE}}"

  _perform-mapping-for-module-items:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      INPUTFOLDER:
        sh: echo "/mapping/input/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      OUTPUTFOLDER:
        sh: echo "/mapping/output/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      DESTINATIONFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      MAPPINGFILE:
        sh: echo "/mapping/mapping-$(echo "{{.MODULE}}" | awk '{print tolower($0)}').x3ml"
    status:
      - '[ "$(find {{.INPUTFOLDER}} -name "*.xml" -type f)" ] || exit 0 && exit 1'
    cmds:
      - mkdir -p {{.OUTPUTFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -delete
      - bash /scripts/performMapping.sh -i {{.INPUTFOLDER}} -o {{.OUTPUTFOLDER}} -m {{.MAPPINGFILE}} -g {{.GENERATOR_POLICY}} -j {{.X3ML_ENDPOINT}}
      - sleep 5s # Wait for the mapping to finish
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastMapped
          VALUE:
            sh: date "+%Y-%m-%d %H:%M:%S.000"
          SOURCEFOLDER: "{{.INPUTFOLDER}}"
          FILEEXTENSION: .xml
      - find {{.INPUTFOLDER}} -maxdepth 1 -name "*.xml" -delete
      - task: _perform-post-mapping-tasks
        vars:
          MODULE: "{{.MODULE}}"
          FOLDER: "{{.OUTPUTFOLDER}}"
      - mkdir -p {{.DESTINATIONFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -exec mv -t {{.DESTINATIONFOLDER}} {} +

  _perform-post-mapping-tasks:
    internal: true
    requires:
      vars: [MODULE, FOLDER]
    cmds:
      - echo "Performing post-mapping tasks for {{.MODULE}}"
      - task: _validate-turtle-files-in-folder
        vars:
          FOLDER: "{{.FOLDER}}"

  _prepare-mapping-for-module-items:
    requires:
      vars: [MODULE]
    vars:
      MODULE: "{{.MODULE}}"
      INPUTFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      OUTPUTFOLDER:
        sh: echo "/mapping/input/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - mkdir -p {{.OUTPUTFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.xml" -delete
      - python /scripts/prepareDataForMapping.py --module {{.MODULE}} --inputFolder {{.INPUTFOLDER}} --outputFolder {{.OUTPUTFOLDER}} {{.CLI_ARGS}}

  _process-items-unpublished-from-museumplus:
    internal: true
    vars: 
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
    interactive: True
    cmds:
      - python /scripts/processUnpublishedItems.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --module {{.MODULE}} --inputFolder {{.INPUT_FOLDER}} --turtleFolder {{.TURTLE_FOLDER}} --namedGraphBase {{.NAMEDGRAPHBASE}} --filenamePrefix {{.FILENAMEPREFIX}} --sparqlEndpoint {{.BLAZEGRAPH_ENDPOINT}}

  _remove-unpublished-module-items:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      TURTLEFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      XMLFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - echo "Checking for unpublished items in {{.MODULE}}"
      - task: _process-items-unpublished-from-museumplus
        vars:
          MODULE: "{{.MODULE}}"
          INPUT_FOLDER: "{{.XMLFOLDER}}"
          TURTLE_FOLDER: "{{.TURTLEFOLDER}}"
          FILENAMEPREFIX: "{{.FILENAMEPREFIX}}"

  _remove-module-items-from-triplestore:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
      ITEMPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      QUERY: |
        PREFIX skkg: <https://ontology.skkg.ch/>
        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
        SELECT DISTINCT ?g WHERE {
          GRAPH ?g {
            ?s a/rdfs:subClassOf* skkg:Entity
          }
          FILTER(STRSTARTS(STR(?g), \"{{.NAMEDGRAPHBASE}}{{.ITEMPREFIX}}\"))
        }
    cmds:
      - echo "Removing {{.MODULE}} items from the triplestore"
      - |
        MAX_RETRIES=5
        RESPONSE=$(curl --silent -X POST "{{.BLAZEGRAPH_ENDPOINT}}?format=json" --data-urlencode "query={{.QUERY}}")
        GRAPHS=$(echo $RESPONSE | jq -r '.results.bindings[].g.value')
        CURRENT_GRAPH_INDEX=1
        TOTAL_NUM_GRAPHS=$(echo $GRAPHS | wc -w)
        RETRY_COUNT=1
        for GRAPH in $GRAPHS; do
          DROP_QUERY="DROP GRAPH <$GRAPH>"
          echo "Dropping graph $CURRENT_GRAPH_INDEX/$TOTAL_NUM_GRAPHS ($GRAPH)"
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            curl --silent -X POST "{{.BLAZEGRAPH_ENDPOINT}}" --data-urlencode "update=$DROP_QUERY" > /dev/null || true
            if [ $? -eq 0 ]; then
              RETRY_COUNT=1
              CURRENT_GRAPH_INDEX=$((CURRENT_GRAPH_INDEX+1))
              break
            else
              echo "Retrying..."
              RETRY_COUNT=$((RETRY_COUNT+1))
              sleep 2
            fi
          done
        done

  _remove-module-items-without-equivalent-ttl-from-triplestore:
    internal: true
    requires:
      vars: [MODULE]
    silent: true
    vars:
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
      ITEMPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      TTLFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      QUERY: |
        PREFIX skkg: <https://ontology.skkg.ch/>
        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
        SELECT DISTINCT ?g WHERE {
          GRAPH ?g {
            ?s a/rdfs:subClassOf* skkg:Entity
          }
          FILTER(STRSTARTS(STR(?g), \"{{.NAMEDGRAPHBASE}}{{.ITEMPREFIX}}\"))
        }
    cmds:
      - echo "Checking for {{.MODULE}} items in the triplestore that do not have an equivalent TTL file..."
      - |
        MAX_RETRIES=5
        RESPONSE=$(curl --silent -X POST "{{.BLAZEGRAPH_ENDPOINT}}?format=json" --data-urlencode "query={{.QUERY}}")
        GRAPHS=$(echo $RESPONSE | jq -r '.results.bindings[].g.value')
        TOTAL_NUM_GRAPHS=$(echo $GRAPHS | wc -w)
        echo "Total number of graphs: $TOTAL_NUM_GRAPHS"
        TTL_FILES=$(find {{.TTLFOLDER}} -type f -name "*.ttl" | xargs -n 1 basename | sed 's/.ttl//')
        TOTAL_NUM_TTL_FILES=$(echo $TTL_FILES | wc -w)
        echo "Total number of TTL files: $TOTAL_NUM_TTL_FILES"
        # For each GRAPH in the triplestore check if there is a corresponding TTL file. If not remove the GRAPH
        RETRY_COUNT=1
        for GRAPH in $GRAPHS; do
          # Extract the GRAPH name from the full URI by removing the NAMEDGRAPHBASE
          GRAPH_NAME="${GRAPH#{{.NAMEDGRAPHBASE}}}"
          if [[ $TTL_FILES == *$GRAPH_NAME* ]]; then
            continue
          else
            DROP_QUERY="DROP GRAPH <$GRAPH>"
            echo "Dropping graph $GRAPH"
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              curl --silent -X POST "{{.BLAZEGRAPH_ENDPOINT}}" --data-urlencode "update=$DROP_QUERY" > /dev/null || true
              if [ $? -eq 0 ]; then
                RETRY_COUNT=1
                break
              else
                echo "Retrying..."
                RETRY_COUNT=$((RETRY_COUNT+1))
                sleep 2
              fi
            done
          fi
        done

  _reset-iiif-and-vocabularies:
    internal: true
    desc: Subtask to reset the IIIF and vocabularies data
    prompt: Do you also want to reset the IIIF and vocabularies data?
    cmds:
      - task: reset-vocabularies
      - task: reset-iiif

  _suggest-alignments:
    internal: True
    interactive: True
    requires:
      vars: [INPUT_FILE, RECONCILIATION_TYPE, BASE_TYPE, RECONCILIATION_TYPE]
    status:
      - |
        # Compare the date of the input file with the date of the output file. if both have been created on the same day, we assume the task is up to date
        INPUT_FILE_DATE=$(date -r {{.INPUT_FILE}} "+%Y-%m-%d")
        OUTPUT_FILE_DATE=$(date -r {{.OUTPUTFILE}} "+%Y-%m-%d")
        if [ "$INPUT_FILE_DATE" == "$OUTPUT_FILE_DATE" ]; then
          exit 0
        else
          exit 1
        fi
    vars:
      LIMIT: 5
      OUTPUTFILE:
        sh: echo "/data/ttl/additional/classifications/$(basename {{.INPUT_FILE}} .ttl)-alignments.ttl"
    cmds:
        - python /scripts/suggestAlignments.py --input_file "{{.INPUT_FILE}}" --reconciliation_type "{{.RECONCILIATION_TYPE}}"  --limit "{{.LIMIT}}" --output_file "{{.OUTPUTFILE}}" --base_type "{{.BASE_TYPE}}" {{if .LOG_FILE}}--log_file "{{.LOG_FILE}}"{{end}}
        - # Set the date of the output file to the current date and time
        - touch -d "$(date "+%Y-%m-%d %H:%M:%S")" {{.OUTPUTFILE}}

  _update-metadata-for-module:
    internal: true
    requires:
      vars: [MODULE, KEY, VALUE, SOURCEFOLDER, FILEEXTENSION]
    vars:
      METADATAFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      SOURCEFOLDER: "{{.SOURCEFOLDER}}"
      KEY: "{{.KEY}}"
      VALUE: "{{.VALUE}}"
      FILEEXTENSION: "{{.FILEEXTENSION}}"
    cmds:
      - python /scripts/updateMetadataValueForFiles.py --metadataFolder {{.METADATAFOLDER}} --inputFolder {{.SOURCEFOLDER}} --key {{.KEY}} --value "{{.VALUE}}" --fileExtension {{.FILEEXTENSION}}

  _validate-turtle-files-in-folder:
    internal: true
    requires:
      vars: [FOLDER]
    vars:
      SHAPES_GRAPH: /mapping/shapesGraph.ttl
      SCHEMA_SKKG: /mapping/schemas/skkg-ontology.ttl
      SCHEMA_CRM: https://cidoc-crm.org/rdfs/7.1.1/CIDOC_CRM_v7.1.1.rdfs
      REPORTS_GRAPH: "{{.NAMESPACE}}graph/shaclReports"
      LIMIT: 50
      TEMP_FOLDER: /data/temp/validate
      FILE_PREFIX: validate-
      REPORT_IRI:
        sh: echo "validation:validation-report-$(echo {{.FOLDER}} | sed 's|/|-|g')-$(date "+%Y-%m-%d-%H-%M-%S")"
    interactive: True
    status:
      - '[ "$(find {{.FOLDER}} -name "*.ttl" -type f)" ] || exit 0 && exit 1'
    cmds:
      - mkdir -p {{.TEMP_FOLDER}}
      - find {{.TEMP_FOLDER}} -type f -name '*.ttl' -delete
      # Validate each file in the folder, outputting the failed tests to temporary turtle files
      - |
        numfiles=$(find {{.FOLDER}} -type f -name '*.ttl' | wc -l)
        count=1
        for f in $(find {{.FOLDER}} -type f -name '*.ttl' | head -n {{.LIMIT}}); do
          echo "Validating file $count of $numfiles: $f"
          pyshacl -s {{.SHAPES_GRAPH}} -e {{.SCHEMA_SKKG}} -e {{.SCHEMA_CRM}} -m -i rdfs -a -j -f turtle $f -o {{.TEMP_FOLDER}}/{{.FILE_PREFIX}}$(basename $f) || true
          # Delete the report output file if it does conform
          if grep -q 'sh:conforms true' {{.TEMP_FOLDER}}/{{.FILE_PREFIX}}$(basename $f); then
            rm {{.TEMP_FOLDER}}/{{.FILE_PREFIX}}$(basename $f)
          fi
          count=$((count+1))
          if [ $count -gt {{.LIMIT}} ]; then
            echo "Notice: Validation is limited to {{.LIMIT}} files. Only the first {{.LIMIT}} files have been validated."
            break
          fi
        done
      # If tests have failed there will be files in the temp folder, output a message to the console
      - |
        if [ "$(find {{.TEMP_FOLDER}} -type f -name '*.ttl' -size +0c | wc -l)" -gt 0 ]; then
          echo "Validation errors found. Check the SHACL reports in the triplestore."
          if [ -n "$SLACK_WEBHOOK_URL" ]; then
            curl -X POST -H 'Content-type: application/json' --data '{"text":"Validation errors found when mapping files in {{.FOLDER}}. Check the SHACL reports in the triplestore."}' "$SLACK_WEBHOOK_URL"
          fi
        else
          echo "Validation successful."
        fi
      - task: _combine_and_ingest_shacl_reports
        vars:
          TEMP_FOLDER: "{{.TEMP_FOLDER}}"
          REPORTS_GRAPH: "{{.REPORTS_GRAPH}}"
          REPORT_SOURCEFOLDER: "{{.FOLDER}}"
          REPORT_IRI: "{{.REPORT_IRI}}"
