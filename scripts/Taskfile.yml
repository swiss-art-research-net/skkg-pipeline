# https://taskfile.dev

version: '3'

vars:
  BLAZEGRAPH_ENDPOINT: http://blazegraph:8080/blazegraph/sparql
  BLAZEGRAPH_ENDPOINT_SECONDARY: http://blazegraph-secondary:8080/blazegraph/sparql
  BLAZEGRAPH_BACKUP: http://blazegraph:8080/blazegraph/backup
  GENERATOR_POLICY: /mapping/generator-policy.xml
  MAPPING_BATCH_SIZE: 10
  NAMESPACE: https://data.skkg.ch/
  OUTPUTFOLDER_DUMP: /data/ttl/dump

output: 'prefixed'

tasks:

  default:
    desc: Runs the entire pipeline
    cmds:
      - '[ $(pgrep -cx "task") -gt 1 ] && echo "Another task is currently being executed. Wait for it to complete before running the pipeline." && exit 1 || echo "Running pipeline..." && exit 0'
      - task: download-source-items
      - task: prepare-and-perform-mapping-for-items
      - task: ingest-items
      - task: ingest-classifications
      - task: ingest-ontologies
      - task: retrieve-and-ingest-additional-data

  create-blazegraph-backup:
    desc: Creates a compressed Blazegraph backup
    vars:
      FILENAME:
        sh: echo "/backup/blazegraph-$(date -u "+%Y-%m-%d-%H-%M-%S").jnl.gz"
    cmds:
       - curl --data-urlencode "file={{.FILENAME}}" --data-urlencode "compress=true" --data-urlencode "block=true" {{.BLAZEGRAPH_BACKUP}}  

  create-data-dump:
    desc: Creates a TTL dump of the data generated by the pipeline
    vars:
      OUTPUTFOLDER: /data/ttl/dump
      FILENAME:
        sh: echo dump-$(date -u "+%Y-%m-%d-%H-%M-%S")
    cmds:
      - mkdir -p {{.OUTPUTFOLDER_DUMP}}
      - rm -f {{.OUTPUTFOLDER_DUMP}}/*.ttl
      - find /data/ttl/main/ -name "*.ttl" -exec cat {} + > {{.OUTPUTFOLDER_DUMP}}/temp.ttl
      - awk '/^@prefix/ && !seen[$0]++ { print }' {{.OUTPUTFOLDER_DUMP}}/temp.ttl > {{.OUTPUTFOLDER_DUMP}}/{{.FILENAME}}.ttl
      - grep -v "^@prefix" {{.OUTPUTFOLDER_DUMP}}/temp.ttl >> {{.OUTPUTFOLDER_DUMP}}/{{.FILENAME}}.ttl
      - rm -f {{.OUTPUTFOLDER_DUMP}}/temp.ttl
      - gzip -c {{.OUTPUTFOLDER_DUMP}}/{{.FILENAME}}.ttl > {{.OUTPUTFOLDER_DUMP}}/{{.FILENAME}}.ttl.gz
      - rm -f {{.OUTPUTFOLDER_DUMP}}/{{.FILENAME}}.ttl
      - # Remove old dumps if NUMBER_OF_DUMPS_TO_KEEP is set
      - if [ -n "$NUMBER_OF_DUMPS_TO_KEEP" ]; then
          ls -t {{.OUTPUTFOLDER_DUMP}}/dump-*.ttl.gz | tail -n +$(($NUMBER_OF_DUMPS_TO_KEEP+1)) | xargs rm -f;
        fi
      - echo "Data dump created at {{.OUTPUTFOLDER_DUMP}}/{{.FILENAME}}.ttl.gz"

  download-source-items:
    desc: Downloads all item records from MuseumPlus
    cmds:
      - for:
          - Address
          - Exhibition
          - Literature
          - Multimedia
          - Object
          - Person
        task: _download-module-items-from-museumplus
        vars:
          MODULE: "{{.ITEM}}"

  download-source-vocabularies:
    desc: Downloads all vocabularies from MuseumPlus
    cmds:
      - for:
          - AdrCountryVgr
          - AdrTypeVgr
          - ExhExternalInternalVgr
          - ExhOrganiserTypeVgr
          - ExhTypeVgr
          - ExhStatusVgr
          - GenCurrencyVgr
          - GenLanguageVgr
          - GenMoveStatusVgr
          - LitAuthorTypeVgr
          - LitLanguageVgr
          - LitTypeVgr
          - LitPlaceVgr
          - LitPersonTypeVgr
          - MulTypeVgr
          - ObjAcquisitionModeVgr
          - ObjCategoryVgr
          - ObjConditionShortVgr
          - ObjDatePeriodVgr
          - ObjDatePrefixVgr
          - ObjDateSourceVgr
          - ObjDateSuffixVgr
          - ObjDateTypeVgr
          - ObjDim3DTypeVgr
          - ObjIconographyVgr
          - ObjIconographyTypeVgr
          - ObjInscriptionDialogTypeVgr
          - ObjInscriptionTypeVgr
          - ObjInscriptionPositionVgr
          - ObjMaterialVgr
          - ObjMaterialTechniqueVgr
          - ObjMaterialTechniqueTypeVgr
          - ObjObjectTitleTypeVgr
          - ObjObjectTitleSourceVgr
          - ObjObjectTypeVgr
          - ObjPerAssociationRoleVgr
          - ObjPerAssociationAttributionVgr
          - ObjTechniqueVgr
          - PerTypeVgr
        task: _download-vocabulary-from-museumplus
        vars:
          VOCABULARY: "{{.ITEM}}"
          
  download-items-for-module:
    desc: Downloads the item records for a specific module from MuseumPlus. Pass the module name as command line argument
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - task: _download-module-items-from-museumplus
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  execute-query-from-file:
    desc: Execute a query against the main Blazegraph instance. Pass the path to the file as command line argument
    cmds:
      - |
        curl -X POST -H "Accept: text/csv" --data-urlencode "query=$(cat "{{.CLI_ARGS}}")" {{.BLAZEGRAPH_ENDPOINT}}

  first-run:
    desc: Task to run when the pipeline is run for the first time
    cmds:
      - task: update-vocabularies
      - task: update-iiif 
      - task: ingest-platform-data

  generate-example-record-address:
    desc: Generates an example Address record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-address-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          MODULE: Address
          INPUTFILES: /data/source/address/address-item-260a0a70-4d26-4f15-8b27-d87243c47c24.xml /data/source/address/address-item-0df1724d-e9e8-4b0c-96db-bc1ee4696000.xml /data/source/address/address-item-0b5918d4-c549-4477-8c82-159314e3b525.xml /data/source/address/address-item-3a7892e0-9d41-4561-9595-42070e0b9e66.xml /data/source/address/address-item-287ee736-19da-4806-a722-c3e389ab8c4a.xml /data/source/address/address-item-0a4ea0e2-f98f-4966-a0df-ab159620d3bf.xml

  generate-example-record-exhibition:
    desc: Generates an example Exhibition record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-exhibition-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          MODULE: Exhibition
          INPUTFILES: /data/source/exhibition/exhibition-item-53b63629-5c82-4614-aecc-7bf3075778a7.xml /data/source/exhibition/exhibition-item-4.xml
  
  generate-example-record-object:
    desc: Generates an example Object record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-object-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          MODULE: Object
          INPUTFILES: /data/source/object/object-item-493.xml /data/source/object/object-item-4f66e941-1bcb-4e14-baab-ffdaef1c3436.xml /data/source/object/object-item-0a5b480f-04d5-4053-840a-5185a2abda39.xml /data/source/object/object-item-0a4c577f-d3e3-4761-bc3c-b8143162780e.xml /data/source/object/object-item-c6b149c2-f809-4d8c-8dc9-70acb24e0070.xml /data/source/object/object-item-3412c1a2-3c87-462a-8943-34aede5dcf5a.xml /data/source/object/object-item-2a0c8fab-5771-496c-9350-5482f50c93e2.xml /data/source/object/object-item-0a5b9c6a-2d1d-43c5-b833-6975ddfa7ded.xml /data/source/object/object-item-3c7215d0-3aba-4bb8-98e6-5da239ab0a64.xml /data/source/object/object-item-0b17827d-117b-42b7-9925-0731f6db779b.xml /data/source/object/object-item-0a0c96ab-71f1-466a-a5ff-ab556d437f15.xml /data/source/object/object-item-ffa356cf-f988-4d96-9580-92dcb0e4dddf.xml
  
  generate-example-record-literature:
    desc: Generates an example Literature record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-literature-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          MODULE: Literature
          INPUTFILES: /data/source/literature/literature-item-b16e2d5f-af15-4a6d-99be-e06af532923e.xml /data/source/literature/literature-item-a50e1a84-367c-4a9f-8357-ebc4fe29badc.xml /data/source/literature/literature-item-710a0732-993d-4d4e-8611-5fe1714c2385.xml /data/source/literature/literature-item-0b6b164a-d7d2-4c58-8f94-9dcf2eb6a9dc.xml /data/source/literature/literature-item-a6fda927-827b-4824-8cfc-2f91dcea74f8.xml /data/source/literature/literature-item-118.xml /data/source/literature/literature-item-0a1ab550-dabb-4afd-be17-f0f43725be33.xml /data/source/literature/literature-item-0b7ee850-6fd8-45ba-af19-267548c9c4cf.xml
  
  generate-example-record-multimedia:
    desc: Generates an example Multimedia record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-multimedia-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          MODULE: Multimedia
          INPUTFILES: /data/source/multimedia/multimedia-item-2063a088-3cc2-4070-b274-fe1fb3d456ee.xml /data/source/multimedia/multimedia-item-08d26839-ab9f-4456-8010-69073551b7c5.xml /data/source/multimedia/multimedia-item-11252.xml /data/source/multimedia/multimedia-item-2270.xml /data/source/multimedia/multimedia-item-8727.xml

  generate-example-record-person:
    desc: Generates an example Person record for developing the mapping in the X3ML editor
    vars:
      OUTPUTFILE: /mapping/example-person-record.xml
    cmds:
      - task: _generate-example-record
        vars:
          OUTPUTFILE: "{{.OUTPUTFILE}}"
          MODULE: Person
          INPUTFILES: /data/source/person/person-item-1111.xml /data/source/person/person-item-88c3cca8-a587-44b8-8c6d-194dd285b1dd.xml /data/source/person/person-item-0d2611a7-961e-420a-8b04-dc628c3f70fb.xml /data/source/person/person-item-f447a4d2-7be1-4d7c-8dcb-64381b20a9bc.xml

  generate-mapping-file-from-3m:
    desc: Generates a mapping file from data stored in the 3M Editor.
    cmds:
      - python /scripts/retrieveMappingFromExist.py {{.CLI_ARGS}}
  
  generate-field-definitions:
    desc: Generates the field definitions for the platform based on the fieldDefinitions.yml file
    sources:
      - /apps/skkg/src/fieldDefinitions.yml
    vars:
      INPUTFILE: /apps/skkg/src/fieldDefinitions.yml
      JSONOUTPUT: /apps/skkg/data/templates/https%3A%2F%2Fstatic.swissartresearch.net%2Fpartial%2FfieldDefinitions.html
      INLINEOUTPUT: /apps/skkg/data/templates/https%3A%2F%2Fstatic.swissartresearch.net%2Fpartial%2FfieldDefinitionsInline.html
    cmds:
      - semantic-field-util -f JSON -y {{.INPUTFILE}}  write -t {{.JSONOUTPUT}}
      - semantic-field-util -f INLINE -y {{.INPUTFILE}}  write -t {{.INLINEOUTPUT}}
  
  ingest-classifications:
    desc: Ingest classifications into the triplestore
    sources:
      - /data/ttl/additional/classifications/*.ttl
    cmds:
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME:
            sh: echo "$(basename {{.ITEM}} .ttl)"
          FILE: "{{.ITEM}}"
          TYPE: application/x-turtle
          GRAPH: 
            sh: echo "{{.NAMESPACE}}graph/classifications/$(basename {{.ITEM}} .ttl)"
          ENDPOINT: "{{.BLAZEGRAPH_ENDPOINT_SECONDARY}}"
  
  ingest-items:
    desc: Ingest items for all modules. Add --debug true To see the response from the triplestore
    cmds:
      - for:
        - object
        - address
        - person
        - multimedia
        - literature
        - exhibition
        task: _ingest_module_items
        vars:
          MODULE: "{{.ITEM}}"

  ingest-iiif:
    desc: Ingest IIIF data into the triplestore
    sources:
      - /data/ttl/main/iiif/*.ttl
    cmds:
      - for: sources
        task: _drop-graph
        vars:
          GRAPH:
            sh: echo "{{.NAMESPACE}}graph/iiif/$(basename {{.ITEM}} .ttl)"
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME:
            sh: echo "$(basename {{.ITEM}} .ttl)"
          FILE: "{{.ITEM}}"
          TYPE: application/x-turtle
          GRAPH: 
            sh: echo "{{.NAMESPACE}}graph/iiif/$(basename {{.ITEM}} .ttl)"
          ENDPOINT: "{{.BLAZEGRAPH_ENDPOINT}}"

  ingest-module-items:
    desc: Ingests the items for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - task: _ingest_module_items
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"
          DEBUG: true
  
  ingest-ontologies:
    desc: Ingests the ontologies into individual named Graphs
    sources:
      - /mapping/schemas/*.*
    cmds:
      - task: _ingest-data-from-file
        vars:
          NAME: CIDOC-CRM
          FILE: /mapping/schemas/CIDOC_CRM_7.1.1_RDFS_Impl_v1.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/cidoc-crm
      - task: _ingest-data-from-file
        vars:
          NAME: CIDOC-CRM PC
          FILE: /mapping/schemas/CIDOC_CRM_v7.1.3_PC.rdf
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/cidoc-crm/pc
      - task: _ingest-data-from-file
        vars:
          NAME: CRMdig
          FILE: /mapping/schemas/CRMdig_v3.2.1.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.ics.forth.gr/isl/CRMdig
      - task: _ingest-data-from-file
        vars:
          NAME: CRMsci
          FILE: /mapping/schemas/CRMsci_v2.0.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://www.cidoc-crm.org/extensions/crmsci
      - task: _ingest-data-from-file
        vars:
          NAME: FRBRoo
          FILE: /mapping/schemas/FRBR2.4.rdfs
          TYPE: application/rdf+xml
          GRAPH: http://iflastandards.info/ns/fr/frbr/frbroo
      - task: _ingest-data-from-file
        vars:
          NAME: Linked.Art
          FILE: /mapping/schemas/LinkedArt.rdfs
          TYPE: application/rdf+xml
          GRAPH: https://linked.art/ns/terms
      - task: _ingest-data-from-file
        vars:
          NAME: SKKG Ontology
          FILE: /mapping/schemas/skkg-ontology.ttl
          TYPE: application/x-turtle
          GRAPH: http://ontology.skkg.ch/ontology

  ingest-platform-data:
    desc: Ingests the data used for the operation of the platform
    sources:
      - /data/platform/*.trig
    cmds: 
      - for: sources
        task: _ingest-data-from-file
        vars:
          NAME: "{{.ITEM}}"
          FILE: "{{.ITEM}}"
          TYPE: application/x-trig

  ingest-vocabularies:
    - task: _ingest_vocabularies
      vars:
        INPUTFOLDER: /data/ttl/main/vocabularies
        NAMESPACE: https://data.skkg.ch/type/

  perform-mapping-for-module-items:
    desc: Performs the mapping for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - task: _perform-mapping-for-module-items
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  prepare-and-perform-mapping-for-items:
    desc: Prepares and performs the mapping for all modules
    cmds:
      - echo "Preparing mapping..."
      - for:
          - Address
          - Exhibition
          - Literature
          - Multimedia
          - Object
          - Person
        task: _prepare-mapping-for-module-items
        vars:
          MODULE: "{{.ITEM}}"
      - echo "Mapping..."
      - for:
          - Address
          - Exhibition
          - Literature
          - Multimedia
          - Object
          - Person
        task: _perform-mapping-for-module-items
        vars:
          MODULE: "{{.ITEM}}"

  prepare-mapping-for-module-items:
    desc: Prepares the mapping for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - task: _prepare-mapping-for-module-items
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"
    
  prepare-and-perform-mapping-for-iiif:
    desc: Performs the mapping for the IIIF data
    sources:
      - /mapping/mapping-iiif.x3ml
      - /data/source/iiif/*.xml
    vars:
      SOURCEFOLDER: /data/source/iiif
      INPUTFOLDER: /mapping/input/iiif
      OUTPUTFOLDER: /data/ttl/main/iiif
      MAPPINGFILE: /mapping/mapping-iiif.x3ml
    cmds:
      - mkdir -p {{.INPUTFOLDER}}
      - mkdir -p {{.OUTPUTFOLDER}}
      - rm -rf {{.INPUTFOLDER}}/*.xml
      - rm -rf {{.OUTPUTFOLDER}}/*.ttl
      - # Copy all XML files from the source folder to the input folder
      - find {{.SOURCEFOLDER}} -maxdepth 1 -name "*.xml" -exec cp -t {{.INPUTFOLDER}} {} +
      - bash /scripts/performMapping.sh -i {{.INPUTFOLDER}} -o {{.OUTPUTFOLDER}} -m {{.MAPPINGFILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}

  perform-mapping-for-vocabularies:
    desc: Performs the mapping for the vocabularies
    sources:
      - /mapping/mapping-vocabulary.x3ml
      - /data/source/vocabularies/*.xml
    vars:
      SOURCEFOLDER: "/data/source/vocabularies"
      INPUTFOLDER: "/mapping/input/vocabularies"
      OUTPUTFOLDER: "/data/ttl/main/vocabularies"
      MAPPINGFILE: "/mapping/mapping-vocabulary.x3ml"
    cmds:
      - mkdir -p {{.INPUTFOLDER}}
      - mkdir -p {{.OUTPUTFOLDER}}
      - # Copy all XML files from the source folder to the input folder
      - find {{.SOURCEFOLDER}} -maxdepth 1 -name "*.xml" -exec cp -t {{.INPUTFOLDER}} {} +
      - # Remove the string 'xmlns="http://www.zetcom.com/ria/ws/vocabulary"' from the XML files in the input folder as X3ML is not able to handle XML namespaces
      - find {{.INPUTFOLDER}} -maxdepth 1 -name "*.xml" -exec sed -i 's/xmlns="http:\/\/www.zetcom.com\/ria\/ws\/vocabulary"//g' {} +
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -delete
      - bash /scripts/performMapping.sh -i {{.INPUTFOLDER}} -o {{.OUTPUTFOLDER}} -m {{.MAPPINGFILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}

  push-latest-data-dump:
    desc: Upload latest data dump to S3 endpoint for data sharing
    vars:
      FILEPATH:
        sh: echo "$(ls -t {{.OUTPUTFOLDER_DUMP}}/*.ttl.gz | head -1)"
      FILENAME:
        sh: echo "$(basename {{.FILEPATH}})"
    cmds:
      - echo "Uploading {{.FILEPATH}} to S3 bucket $S3_BUCKET_PUSH..."
      - aws s3 cp "{{.FILEPATH}}" s3://$S3_BUCKET_PUSH/{{.FILENAME}}
  
  recreate-folder-metadata:
    desc: Recreate the metadata for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
    cmds:
      - rm -f /data/source/{{.MODULE}}/metadata.json
      - python /scripts/recreateMetadata.py --folder /data/source/{{.MODULE}}

  remove-deleted-module-items:
    desc: Removes item records that have been deleted from MuseumPlus for a specific module. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST: 
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - echo "Removing deleted {{.MODULE}} items..."
      - task: _remove-deleted-module-items
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  remove-deleted-items:
    desc: Removes all item records that have been deleted from MuseumPlus
    cmds:
      - for:
          - Address
          - Exhibition
          - Literature
          - Multimedia
          - Object
          - Person
        task: _remove-deleted-module-items
        vars:
          MODULE: "{{.ITEM}}"

  remove-module-items-from-triplestore:
    desc: Removes all item records for a specific module from the triplestore. The module name should be passed as an argument or via the MODULE variable.
    prompt: This will remove all item records for the module {{.MODULE_UCFIRST}} from the triplestore. Do you want to continue?
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - task: _remove-module-items-from-triplestore
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"
      - task: reset-last-ingested-metadata
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  remove-module-items-without-equivalent-ttl-from-triplestore:
    desc: Removes all item records for a specific module from the triplestore that do not have an equivalent TTL file. The module name should be passed as an argument or via the MODULE variable.
    interactive: True
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - task: _remove-module-items-without-equivalent-ttl-from-triplestore
        vars:
          MODULE: "{{.MODULE_UCFIRST}}"

  retrieve-and-ingest-additional-data:
    desc: Retrieve and ingest additional data for external URIs in the Triple Store 
    interactive: True
    vars:
      OUTPUTFOLDER: /data/ttl/additional/external
      PREDICATES: http://www.ics.forth.gr/isl/CRMdig/L54_is_same-as,http://www.cidoc-crm.org/cidoc-crm/P2_has_type
      SOURCES: gnd,aat
      INGEST: True
      INGESTUPDATE: True
      INGESTNAMESPACE: https://data.skkg.ch/graph/externalData/
    cmds:
      - python /scripts/retrieveAdditionalData.py --endpoint {{.BLAZEGRAPH_ENDPOINT}} --outputFolder {{.OUTPUTFOLDER}} --predicates "{{.PREDICATES}}" --ingest {{.INGEST}} --ingestNamespace {{.INGESTNAMESPACE}} --ingestUpdate {{.INGESTUPDATE}}

  retrieve-iiif-data:
    desc: Downloads and prepares data related to the IIIF images
    vars:
      OUTPUTFOLDER: /data/source/iiif
    cmds:
      - mkdir -p {{.OUTPUTFOLDER}}
      - python /scripts/retrieveIiifData.py --input $IIIF_CSV_URL --outputFolder {{.OUTPUTFOLDER}} --filename iiifPaths
 
  reset:
    desc: Delete all artefacts produced by the pipeline.
    prompt: This will delete all artefacts produced by the pipeline... Do you want to continue?
    cmds:
      - rm -f /scripts/.task/checksum/*
      - for:
          - Address
          - Exhibition
          - Literature
          - Multimedia
          - Object
          - Person
        task: reset-module
        vars:
          MODULE: "{{.ITEM}}"
      - task: _reset-iiif-and-vocabularies
      - echo "Done!"

  reset-iiif:
    desc: Delete all artefacts produced by the pipeline for the iiif data.
    cmds: 
      - rm -rf /data/ttl/main/iiif
      - rm -rf /mapping/input/iiif
      - rm -rf /mapping/output/iiif

  reset-module:
    desc: Delete all artefacts produced by the pipeline for a given module. The module name should be passed as an argument or via the MODULE variable.
    silent: true
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      MODULE_LOWERCASE:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      MODULE_UCFIRST:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print toupper(substr($0,0,1)) tolower(substr($0,2))}')"
    cmds:
      - |
        if [ -z "{{.MODULE}}" ]; then
          echo "No module specified as variable or cli argument. Exiting script."
          exit 1
        fi
      - echo "Deleting files for {{.MODULE}}..."
      - rm -rf /data/temp/download/temp_{{.MODULE_UCFIRST}}
      - rm -rf /data/temp/ingest/{{.MODULE_LOWERCASE}}
      - rm -rf /data/ttl/main/{{.MODULE_LOWERCASE}}
      - rm -rf /mapping/input/{{.MODULE_LOWERCASE}}
      - rm -rf /mapping/output/{{.MODULE_LOWERCASE}}
      - echo "Resetting metadata for {{.MODULE}}.."
      - task: recreate-folder-metadata
        vars:
          MODULE: "{{.MODULE_LOWERCASE}}"

  reset-vocabularies:
    desc: Delete all artefacts produced by the pipeline for the vocabularies.
    cmds: 
      - rm -rf /data/ttl/main/vocabularies
      - rm -rf /mapping/input/vocabularies
      - rm -rf /mapping/output/vocabularies

  reset-last-ingested-metadata:
    desc: Resets the last ingested metadata for a specific module. The module name should be passed as an argument or via the MODULE variable.
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      SOURCEFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastIngested
          VALUE: "1970-01-01 00:00:00.000"
          SOURCEFOLDER: "{{.SOURCEFOLDER}}"
          FILEEXTENSION: .xml

  reset-last-mapped-metadata:
    desc: Resets the last mapped metadata for a specific module. The module name should be passed as an argument or via the MODULE variable.
    vars:
      MODULE:
        sh: |
          if [ -z "{{.MODULE}}" ]; then
            echo "{{.CLI_ARGS}}"
          else
            echo "{{.MODULE}}"
          fi
      SOURCEFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastMapped
          VALUE: "1970-01-01 00:00:00.000"
          SOURCEFOLDER: "{{.SOURCEFOLDER}}"
          FILEEXTENSION: .xml
  
  suggest-alignments-for-vocabularies:
    desc: Suggest alignments for all vocabularies with GND data
    sources:
      - /data/ttl/main/vocabularies/*.ttl
    cmds:
      - for: sources
        task: _suggest-alignments
        vars:
          INPUT_FILE: "{{.ITEM}}"
          RECONCILIATION_TYPE: SubjectHeading
          BASE_TYPE: https://ontology.skkg.ch/Type
          LOG_FILE: /logs/suggest-alignments-for-vocabularies.log

  update-iiif:
    desc: Downloads, maps, and ingests the IIIF data
    cmds: 
      - task: retrieve-iiif-data
      - task: prepare-and-perform-mapping-for-iiif
      - task: ingest-iiif

  update-vocabularies:
    desc: Downloads, maps, and ingests the vocabularies
    cmds:
      - task: download-source-vocabularies
      - task: perform-mapping-for-vocabularies
      - sleep 5s
      - task: suggest-alignments-for-vocabularies
      - task: ingest-vocabularies
  
  validate-turtle-file:
    desc: Validate a Turtle file using SHACL. Pass the file to validate through command line argument
    cmds:
      - pyshacl -s /mapping/shapesGraph.ttl -e /mapping/schemas/skkg-ontology.ttl -e https://cidoc-crm.org/rdfs/7.1.1/CIDOC_CRM_v7.1.1.rdfs -m -i rdfs -a -j -f human {{.CLI_ARGS}}

  _download-vocabulary-from-museumplus:
    internal: true
    requires:
      vars: [VOCABULARY]
    vars:
      OUTPUT_FOLDER: /data/source/vocabularies
    cmds:
      - echo "Downloading {{.VOCABULARY}} vocabulary from MuseumPlus"
      - mkdir -p {{.OUTPUT_FOLDER}}
      - python /scripts/downloadVocabulary.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --vocabulary {{.VOCABULARY}} --outputFolder {{.OUTPUT_FOLDER}}

  _download-module-items-from-museumplus:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      FOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
    cmds:
      - echo "Downloading {{.MODULE}} items from MuseumPlus"
      - mkdir -p {{.FOLDER}}
      - task: _download-items-from-museumplus
        vars:
          MODULE: "{{.MODULE}}"
          OUTPUT_FOLDER: "{{.FOLDER}}"
          FILENAMEPREFIX: "{{.FILENAMEPREFIX}}"

  _download-items-from-museumplus:
    internal: true
    requires:
      vars: [MODULE, OUTPUT_FOLDER, FILENAMEPREFIX]
    vars:
      TEMP_FOLDER: /data/temp/download/temp_{{.MODULE}}
    interactive: True
    cmds:
      - mkdir -p {{.TEMP_FOLDER}}
      - python /scripts/downloadItems.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --module {{.MODULE}} --outputFolder {{.OUTPUT_FOLDER}} --tempFolder {{.TEMP_FOLDER}} --filenamePrefix {{.FILENAMEPREFIX}} {{.CLI_ARGS}}

  _drop-graph:
    internal: true
    cmds:
      - curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <{{.GRAPH}}>" > /dev/null

  _generate-example-record:
    internal: true
    requires:
      vars: [OUTPUTFILE, INPUTFILES, MODULE]
    vars:
      OUTPUTFILE: "{{.OUTPUTFILE}}"
      INPUTFILES: "{{.INPUTFILES}}"
      MODULE: "{{.MODULE}}"
    cmds:
      - cat {{.INPUTFILES}} > {{.OUTPUTFILE}}
      - sed -i 's/<application xmlns="http:\/\/www.zetcom.com\/ria\/ws\/module">//g' {{.OUTPUTFILE}}
      - sed -i 's/<modules>//g' {{.OUTPUTFILE}}
      - sed -i 's/<\/modules>//g' {{.OUTPUTFILE}}
      - sed -i 's/<\/application>//g' {{.OUTPUTFILE}}
      - echo '<application><modules>' | cat - {{.OUTPUTFILE}} > temp && mv temp {{.OUTPUTFILE}}; echo '</modules></application>' >> {{.OUTPUTFILE}}
      - python /scripts/applyPreprocessingForExampleRecord.py --file {{.OUTPUTFILE}} --module {{.MODULE}}

  _ingest-data-from-file:
    internal: true
    vars:
      ENDPOINT: 
        sh: echo "{{if .ENDPOINT}}{{.ENDPOINT}}{{else}}{{.BLAZEGRAPH_ENDPOINT}}{{end}}"
    cmds:
      - echo "Ingest {{.NAME}}"
      - curl --silent -X POST {{.ENDPOINT}} --data-urlencode 'update={{if .GRAPH}}DROP GRAPH <{{.GRAPH}}>{{end}}'
      - curl -X POST -H 'Content-Type:{{.TYPE}}' --data-binary '@{{.FILE}}' {{.ENDPOINT}}{{if .GRAPH}}?context-uri={{.GRAPH}}{{end}}

  _ingest_module_items:
    internal: true
    requires:
      vars: [MODULE, NAMESPACE]
    vars:
      INPUTFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      TEMPFOLDER:
        sh: echo "/data/temp/ingest/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      XMLFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
      DEBUG:
        sh: |
          # Your input string of arguments
          args="{{.CLI_ARGS}}"
          # Check if "--debug" is present in the input string
          if [[ "$args" == *"--debug"* ]]; then
            # Use parameter expansion to extract the value after "--debug"
            value="${args#*--debug }"
            # Split the arguments by space and get the first part as the value
            value="${value%% *}"
            echo "$value"
          else
            if [ -z "{{.DEBUG}}" ]; then
              echo "false"
            else
              echo "{{.DEBUG}}"
            fi
          fi
    interactive: True
    cmds:
      - mkdir -p {{.TEMPFOLDER}}
      - |
        # If folder contains already ingested files we skip the preparation step
        if [ "$(find {{.TEMPFOLDER}} -type f -name '*.ttl.ingested' | wc -l)" -gt 0 ]; then
          echo "Skipping preparation step for {{.MODULE}} as there are already ingested files"
        else
          echo "Preparing {{.MODULE}} for ingest"
          python prepareDataForIngest.py  --inputFolder {{.INPUTFOLDER}} --outputFolder {{.TEMPFOLDER}} --xmlFolder {{.XMLFOLDER}}
        fi
      - |
        numfiles=$(find {{.TEMPFOLDER}} -type f -name '*.ttl' | wc -l)        
        count=1
        for f in $(find {{.TEMPFOLDER}} -type f -name '*.ttl' ); do
          identifier=$(basename "$f" | sed "s/{{.FILENAMEPREFIX}}//; s/\\.ttl//")
          graph="{{.NAMEDGRAPHBASE}}{{.FILENAMEPREFIX}}$identifier"
          echo "Ingesting {{.MODULE}} item $count of $numfiles into graph $graph"
          # Drop graph
          curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <$graph>" {{if eq .DEBUG "true"}}{{else}} > /dev/null{{end}}
          # Ingest into graph
          curl --silent -X POST --data-binary "uri=file://$f" "{{.BLAZEGRAPH_ENDPOINT}}?context-uri=$graph" {{if eq .DEBUG "true"}}{{else}} > /dev/null{{end}}
          count=$((count+1)) 
          mv $f $f.ingested
        done
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastIngested
          VALUE:
            sh: date -u "+%Y-%m-%d %H:%M:%S.000"
          SOURCEFOLDER: "{{.TEMPFOLDER}}"
          FILEEXTENSION: .ttl.ingested
      - find {{.TEMPFOLDER}} -maxdepth 1 -name "*.ttl.ingested" -delete
  
  _ingest_vocabularies:
    internal: true
    requires:
      vars: [INPUTFOLDER, NAMESPACE]
    vars:
      NAMESPACE: "{{.NAMESPACE}}"
    cmds:
      - echo "Ingesting vocabularies"
      - |
        numfiles=$(find {{.INPUTFOLDER}} -type f -name '*.ttl' | wc -l)
        count=1
        for f in $(find {{.INPUTFOLDER}} -type f -name '*.ttl' ); do
          uri=$(grep -oPm 1 '(<{{.NAMESPACE}})[0-9]+' $f) 
          # Strip < at beginning and end of uri
            graph=${uri:1}
          echo -e "Ingesting vocabulary $graph ($count of $numfiles)"
          # Drop graph
          curl --silent -X POST {{.BLAZEGRAPH_ENDPOINT}} --data-urlencode "update=DROP GRAPH <$graph>" > /dev/null
          # Ingest vocabulary into graph
          curl --silent -X POST --data-binary "uri=file://$f" "{{.BLAZEGRAPH_ENDPOINT}}?context-uri=$graph"
          count=$((count+1)) 
        done

  _perform-mapping-for-module-items:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      INPUTFOLDER:
        sh: echo "/mapping/input/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      OUTPUTFOLDER:
        sh: echo "/mapping/output/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      DESTINATIONFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      MAPPINGFILE:
        sh: echo "/mapping/mapping-$(echo "{{.MODULE}}" | awk '{print tolower($0)}').x3ml"
    cmds:
      - mkdir -p {{.OUTPUTFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -delete
      - bash /scripts/performMapping.sh -i {{.INPUTFOLDER}} -o {{.OUTPUTFOLDER}} -m {{.MAPPINGFILE}} -g {{.GENERATOR_POLICY}} -b {{.MAPPING_BATCH_SIZE}}
      - sleep 5s # Wait for the mapping to finish
      - task: _update-metadata-for-module
        vars:
          MODULE: "{{.MODULE}}"
          KEY: lastMapped
          VALUE:
            sh: date -u "+%Y-%m-%d %H:%M:%S.000"
          SOURCEFOLDER: "{{.INPUTFOLDER}}"
          FILEEXTENSION: .xml
      - task: _perform-post-mapping-tasks
        vars:
          MODULE: "{{.MODULE}}"
          FOLDER: "{{.OUTPUTFOLDER}}"
      - mkdir -p {{.DESTINATIONFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.ttl" -exec mv -t {{.DESTINATIONFOLDER}} {} +

  _perform-post-mapping-tasks:
    internal: true
    requires:
      vars: [MODULE, FOLDER]
    cmds:
      - echo "Performing post-mapping tasks for {{.MODULE}}"
      - task: _validate-turtle-files-in-folder
        vars:
          FOLDER: "{{.FOLDER}}"

  _prepare-mapping-for-module-items:
    requires:
      vars: [MODULE]
    vars:
      MODULE: "{{.MODULE}}"
      INPUTFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      OUTPUTFOLDER:
        sh: echo "/mapping/input/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
    cmds:
      - # TODO: separate preparation script (e.g. enrichment of data) from mapping preparation (i.e. moving relevant xml files to a place where they should be mapped)
      - mkdir -p {{.OUTPUTFOLDER}}
      - find {{.OUTPUTFOLDER}} -maxdepth 1 -name "*.xml" -delete
      - python /scripts/prepareDataForMapping.py --module {{.MODULE}} --inputFolder {{.INPUTFOLDER}} --outputFolder {{.OUTPUTFOLDER}} {{.CLI_ARGS}}

  _process-items-deleted-from-museumplus:
    internal: true
    vars: 
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
    interactive: True
    cmds:
      - python /scripts/processDeletedItems.py --url $MUSEUMPLUS_URL --username $MUSEUMPLUS_USERNAME --password $MUSEUMPLUS_PASSWORD --module {{.MODULE}} --inputFolder {{.INPUT_FOLDER}} --namedGraphBase {{.NAMEDGRAPHBASE}} --filenamePrefix {{.FILENAMEPREFIX}} --sparqlEndpoint {{.BLAZEGRAPH_ENDPOINT}}

  _remove-deleted-module-items:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      FOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      FILENAMEPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
    cmds:
      - echo "Checking for deleted items in {{.MODULE}}"
      - task: _process-items-deleted-from-museumplus
        vars:
          MODULE: "{{.MODULE}}"
          INPUT_FOLDER: "{{.FOLDER}}"
          FILENAMEPREFIX: "{{.FILENAMEPREFIX}}"

  _remove-module-items-from-triplestore:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
      ITEMPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      QUERY: |
        PREFIX skkg: <https://ontology.skkg.ch/>
        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
        SELECT DISTINCT ?g WHERE {
          GRAPH ?g {
            ?s a/rdfs:subClassOf* skkg:Entity
          }
          FILTER(STRSTARTS(STR(?g), \"{{.NAMEDGRAPHBASE}}{{.ITEMPREFIX}}\"))
        }
    cmds:
      - echo "Removing {{.MODULE}} items from the triplestore"
      - |
        MAX_RETRIES=5
        RESPONSE=$(curl --silent -X POST "{{.BLAZEGRAPH_ENDPOINT}}?format=json" --data-urlencode "query={{.QUERY}}")
        GRAPHS=$(echo $RESPONSE | jq -r '.results.bindings[].g.value')
        CURRENT_GRAPH_INDEX=1
        TOTAL_NUM_GRAPHS=$(echo $GRAPHS | wc -w)
        RETRY_COUNT=1
        for GRAPH in $GRAPHS; do
          DROP_QUERY="DROP GRAPH <$GRAPH>"
          echo "Dropping graph $CURRENT_GRAPH_INDEX/$TOTAL_NUM_GRAPHS ($GRAPH)"
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            curl --silent -X POST "{{.BLAZEGRAPH_ENDPOINT}}" --data-urlencode "update=$DROP_QUERY" > /dev/null || true
            if [ $? -eq 0 ]; then
              RETRY_COUNT=1
              CURRENT_GRAPH_INDEX=$((CURRENT_GRAPH_INDEX+1))
              break
            else
              echo "Retrying..."
              RETRY_COUNT=$((RETRY_COUNT+1))
              sleep 2
            fi
          done
        done

  _remove-module-items-without-equivalent-ttl-from-triplestore:
    internal: true
    requires:
      vars: [MODULE]
    vars:
      NAMEDGRAPHBASE: "{{.NAMESPACE}}graph/"
      ITEMPREFIX:
        sh: echo "$(echo "{{.MODULE}}" | awk '{print tolower($0)}')-item-"
      TTLFOLDER:
        sh: echo "/data/ttl/main/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      QUERY: |
        PREFIX skkg: <https://ontology.skkg.ch/>
        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
        SELECT DISTINCT ?g WHERE {
          GRAPH ?g {
            ?s a/rdfs:subClassOf* skkg:Entity
          }
          FILTER(STRSTARTS(STR(?g), \"{{.NAMEDGRAPHBASE}}{{.ITEMPREFIX}}\"))
        }
    cmds:
      - echo "Removing {{.MODULE}} items from the triplestore that do not have an equivalent TTL file"
      - |
        MAX_RETRIES=5
        RESPONSE=$(curl --silent -X POST "{{.BLAZEGRAPH_ENDPOINT}}?format=json" --data-urlencode "query={{.QUERY}}")
        GRAPHS=$(echo $RESPONSE | jq -r '.results.bindings[].g.value')
        TOTAL_NUM_GRAPHS=$(echo $GRAPHS | wc -w)
        echo "Total number of graphs: $TOTAL_NUM_GRAPHS"
        TTL_FILES=$(find {{.TTLFOLDER}} -type f -name "*.ttl" | xargs -n 1 basename | sed 's/.ttl//')
        TOTAL_NUM_TTL_FILES=$(echo $TTL_FILES | wc -w)
        echo "Total number of TTL files: $TOTAL_NUM_TTL_FILES"
        # For each GRAPH in the triplestore check if there is a corresponding TTL file. If not remove the GRAPH
        RETRY_COUNT=1
        for GRAPH in $GRAPHS; do
          GRAPH_NAME="${GRAPH#{{.NAMEDGRAPHBASE}}}"
          if [[ $TTL_FILES == *$GRAPH_NAME* ]]; then
            continue
          else
            DROP_QUERY="DROP GRAPH <$GRAPH>"
            echo "Dropping graph $GRAPH"
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              curl --silent -X POST "{{.BLAZEGRAPH_ENDPOINT}}" --data-urlencode "update=$DROP_QUERY" > /dev/null || true
              if [ $? -eq 0 ]; then
                RETRY_COUNT=1
                break
              else
                echo "Retrying..."
                RETRY_COUNT=$((RETRY_COUNT+1))
                sleep 2
              fi
            done
          fi
        done

  _reset-iiif-and-vocabularies:
    internal: true
    desc: Subtask to reset the IIIF and vocabularies data
    prompt: Do you also want to reset the IIIF and vocabularies data?
    cmds:
      - task: reset-vocabularies
      - task: reset-iiif

  _suggest-alignments:
    internal: True
    interactive: True
    requires:
      vars: [INPUT_FILE, RECONCILIATION_TYPE, BASE_TYPE, RECONCILIATION_TYPE]
    vars:
      LIMIT: 5
      OUTPUTFILE:
        sh: echo "/data/ttl/additional/classifications/$(basename {{.INPUT_FILE}} .ttl)-alignments.ttl"
    cmds:
        - python /scripts/suggestAlignments.py --input_file "{{.INPUT_FILE}}" --reconciliation_type "{{.RECONCILIATION_TYPE}}"  --limit "{{.LIMIT}}" --output_file "{{.OUTPUTFILE}}" --base_type "{{.BASE_TYPE}}" {{if .LOG_FILE}}--log_file "{{.LOG_FILE}}"{{end}}

  _update-metadata-for-module:
    internal: true
    requires:
      vars: [MODULE, KEY, VALUE, SOURCEFOLDER, FILEEXTENSION]
    vars:
      METADATAFOLDER:
        sh: echo "/data/source/$(echo "{{.MODULE}}" | awk '{print tolower($0)}')"
      SOURCEFOLDER: "{{.SOURCEFOLDER}}"
      KEY: "{{.KEY}}"
      VALUE: "{{.VALUE}}"
      FILEEXTENSION: "{{.FILEEXTENSION}}"
    cmds:
      - python /scripts/updateMetadataValueForFiles.py --metadataFolder {{.METADATAFOLDER}} --inputFolder {{.SOURCEFOLDER}} --key {{.KEY}} --value "{{.VALUE}}" --fileExtension {{.FILEEXTENSION}}

  _validate-turtle-files-in-folder:
    internal: true
    requires:
      vars: [FOLDER]
    vars:
      SHAPES_GRAPH: /mapping/shapesGraph.ttl
      SCHEMA_SKKG: /mapping/schemas/skkg-ontology.ttl
      REPORTS_GRAPH: "{{.NAMESPACE}}graph/shaclReports"
      LIMIT: 100
    interactive: True
    cmds:
      - python /scripts/validateTurtleWithShacl.py --directory "{{.FOLDER}}" --shapesGraph {{.SHAPES_GRAPH}} --ontologyFile {{.SCHEMA_SKKG}} --endpoint {{.BLAZEGRAPH_ENDPOINT}} --namedGraph {{.REPORTS_GRAPH}} --limit {{.LIMIT}} {{if .DEBUG}}--debug{{end}}